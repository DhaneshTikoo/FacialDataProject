{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhaneshTikoo/FacialDataProject/blob/main/FacialDataProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction"
      ],
      "metadata": {
        "id": "8QodaOiT-Xmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intro about what this is and how to use it"
      ],
      "metadata": {
        "id": "RTxBt5cg-6n4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#File Locations\n"
      ],
      "metadata": {
        "id": "blFMC-m0-ZsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In your Google Drive, make a folder called \"Facial Data\"\n",
        "\n",
        "Place all the Facial Data files in your Google Drive. Make sure they are in the folder you just\n",
        "\n",
        "If you want to place the files somewhere else, you can modify the file paths below."
      ],
      "metadata": {
        "id": "6Arv2fGV_Q7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting default file paths\n",
        "myPath = '/content/drive/MyDrive/Facial Data'\n",
        "outputPath = myPath + '/output'"
      ],
      "metadata": {
        "id": "L1u07GM4-DNk"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Start"
      ],
      "metadata": {
        "id": "1NBYCC60-b-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, press the \"Runtime\" button and click \"Run All\"\n",
        "If Google gives you warnings, click \"Run anyways.\"\n",
        "Additionally, you will need to connect your Google Drive to Google Colab, so make sure to sign in to Google when prompted to mount your Google Drive."
      ],
      "metadata": {
        "id": "M96PIATF_n3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "wykT-EXpMt69"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B0OoZubwSh7"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "_CCMDl6YR1qG"
      },
      "outputs": [],
      "source": [
        "# importing needed modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from operator import itemgetter\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if mpld3 is not already installed, install it\n",
        "installedPackages = !pip list -v\n",
        "installed = False\n",
        "for package in installedPackages:\n",
        "  if package[0:5] == 'mpld3':\n",
        "    installed = True\n",
        "if installed == False:\n",
        "  !pip install mpld3\n",
        "\n",
        "# import mpld3\n",
        "import mpld3"
      ],
      "metadata": {
        "id": "5dNQYXclQgCO"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIeDknEwFL5m"
      },
      "source": [
        "##Setup Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "BZoI285nFLdO"
      },
      "outputs": [],
      "source": [
        "def importData(myfile, myPath):\n",
        "  \"\"\"\n",
        "  imports the data from the file to a dataframe\n",
        "  myFile: string\n",
        "    the name of the text file where the data is located, including the filetype suffix\n",
        "  myPath: string\n",
        "    the path where the file is stored\n",
        "\n",
        "  returns:\n",
        "    imported dataframe\n",
        "  \"\"\"\n",
        "  pathFull = myPath + \"/\" + myfile\n",
        "  data = pd.read_csv(pathFull, header = None, skiprows=22)\n",
        "  data.columns = my_cols\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ZSaNw1NGFUWv"
      },
      "outputs": [],
      "source": [
        "def derivative(x,y):\n",
        "  \"\"\"\n",
        "  inputs x and y lists and returns the x and y lists for that graph's derivative:\n",
        "  reduces the length of x by 1 and takes the derivative of y\n",
        "  x: list, array\n",
        "  y: list, array\n",
        "    the x and y lists for a graph\n",
        "\n",
        "  returns:\n",
        "    the modified x and y lists\n",
        "  \"\"\"\n",
        "  dydx = np.diff(y)/np.diff(x)\n",
        "  dydx_x = x[:-1]\n",
        "  return dydx_x, dydx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Qp4i0xh7FXmB"
      },
      "outputs": [],
      "source": [
        "def generateDerivativeFrames(df):\n",
        "  \"\"\"\n",
        "  creates dataframes for the derivatives of a dataframe's columns\n",
        "  data: dataframe\n",
        "    the name of the text file where the data is located, including the filetype suffix\n",
        "\n",
        "  returns:\n",
        "    der1: the first derivative of the columns of data\n",
        "    der2: the second derivative of the columns of data\n",
        "  \"\"\"\n",
        "  der1 = pd.DataFrame()\n",
        "  der2 = pd.DataFrame()\n",
        "\n",
        "  # create derivative 1\n",
        "  der1 = pd.concat([der1, df[\"bs\"][:-1]], axis=1)\n",
        "  der1 = pd.concat([der1, df[Milliseconds][:-1]], axis=1)\n",
        "  for col in df.columns[2:]:\n",
        "    column = df[col]\n",
        "    x = []\n",
        "    x, column_der = derivative(df[Milliseconds], column)\n",
        "    column_der = pd.Series(column_der)\n",
        "    der1 = pd.concat([der1, column_der.rename(col)], axis=1)\n",
        "\n",
        "  # create derivative 2\n",
        "  der2 = pd.concat([der2, df[\"bs\"][:-2]], axis=1)\n",
        "  der2 = pd.concat([der2, df[Milliseconds][:-2]], axis=1)\n",
        "  for col in der1.columns[2:]:\n",
        "    column = der1[col]\n",
        "    x = []\n",
        "    x, column_der2 = derivative(der1[Milliseconds], column)\n",
        "    column_der2 = pd.Series(column_der2)\n",
        "    der2 = pd.concat([der2, column_der2.rename(col)], axis=1)\n",
        "\n",
        "  return der1, der2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mount Drive & Make Output Directory"
      ],
      "metadata": {
        "id": "ZCZ1A-F3FNno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# make output dir\n",
        "if not os.path.exists(outputPath):\n",
        "  os.mkdir(outputPath)"
      ],
      "metadata": {
        "id": "ogtZe2H7FQMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb26e095-9b11-4137-c8fb-6b8c0a828c5b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zht61QeWLure"
      },
      "source": [
        "##Establish Variables"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a default dataframe\n",
        "data = pd.DataFrame()"
      ],
      "metadata": {
        "id": "I2v5ZIbuHbd7"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "89QZGFHEKh2d"
      },
      "outputs": [],
      "source": [
        "# setting column titles to correspond to the blendshapes they represent\n",
        "my_cols = ['bs', 'Milliseconds', 'head x', 'head y', 'head z', 'EA x', 'EA y',\n",
        "       'EA z', 'LE x', 'LE y', 'RE x', 'RE y', 'browInnerUp', 'browDown_L',\n",
        "       'browDown_R', 'browOuterUp_L', 'browOuterUp_R', 'eyeLookUp_L',\n",
        "       'eyeLookUp_R', 'eyeLookDown_L', 'eyeLookDown_R', 'eyeLookIn_L',\n",
        "       'eyeLookIn_R', 'eyeLookOut_L', 'eyeLookOut_R', 'eyeBlink_L',\n",
        "       'eyeBlink_R', 'eyeSquint_L', 'eyeSquint_R', 'eyeWide_L', 'eyeWide_R',\n",
        "       'cheekPuff', 'cheekSquint_L', 'cheekSquint_R', 'noseSneer_L',\n",
        "       'noseSneer_R', 'jawOpen', 'jawForward', 'jawLeft', 'jawRight',\n",
        "       'mouthFunnel', 'mouthPucker', 'mouthLeft', 'mouthRight',\n",
        "       'mouthRollUpper', 'mouthRollLower', 'mouthShrugUpper',\n",
        "       'mouthShrugLower', 'mouthClose', 'mouthSmile_L', 'mouthSmile_R',\n",
        "       'mouthFrown_L', 'mouthFrown_R', 'mouthDimple_L', 'mouthDimple_R',\n",
        "       'mouthUpperUp_L', 'mouthUpperUp_R', 'mouthLowerDown_L',\n",
        "       'mouthLowerDown_R', 'mouthPress_L', 'mouthPress_R', 'mouthStretch_L',\n",
        "       'mouthStretch_R', 'tongueOut']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "Cwab_Umuxtaa"
      },
      "outputs": [],
      "source": [
        "# defining pairs of columns\n",
        "colPairs = {\n",
        "  'EulerAngles': ['EA x', 'EA y'],\n",
        "  'EyeX':['LE x', 'RE x'],\n",
        "  'EyeY': ['LE y', 'RE y'],\n",
        "  'browDown':['browDown_L', 'browDown_R'],\n",
        "  'browOuterUp':['browOuterUp_L', 'browOuterUp_R'],\n",
        "  'eyeLookUp':['eyeLookUp_L', 'eyeLookUp_R'],\n",
        "  'eyeLookDown':['eyeLookDown_L', 'eyeLookDown_R'],\n",
        "  'eyeLookIn':['eyeLookIn_L', 'eyeLookIn_R'],\n",
        "  'eyeLookOut':['eyeLookOut_L', 'eyeLookOut_R'],\n",
        "  'eyeBlink':['eyeBlink_L', 'eyeBlink_R'], \n",
        "  'eyeSquint':['eyeSquint_L', 'eyeSquint_R'], \n",
        "  'eyeWide':['eyeWide_L', 'eyeWide_R'],\n",
        "  'cheekSquint':['cheekSquint_L', 'cheekSquint_R'], \n",
        "  'noseSneer':['noseSneer_L', 'noseSneer_R'], \n",
        "  'jaw':['jawLeft', 'jawRight'],\n",
        "  'mouth':['mouthLeft', 'mouthRight'],\n",
        "  'mouthRoll':['mouthRollUpper', 'mouthRollLower'] ,\n",
        "  'mouthShrug':['mouthShrugUpper',  'mouthShrugLower'], \n",
        "  'mouthSmile':['mouthSmile_L', 'mouthSmile_R'],\n",
        "  'mouthFrown':['mouthFrown_L', 'mouthFrown_R'], \n",
        "  'mouthDimple':['mouthDimple_L', 'mouthDimple_R'],\n",
        "  'mouthUpper':['mouthUpperUp_L', 'mouthUpperUp_R'],\n",
        "  'mouthLower':['mouthLowerDown_L','mouthLowerDown_R'], \n",
        "  'mouthPress':['mouthPress_L', 'mouthPress_R'], \n",
        "  'mouthStretch':['mouthStretch_L','mouthStretch_R']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "YFLXq-o_KulZ"
      },
      "outputs": [],
      "source": [
        "# defines Milliseconds as the string of the millisecond column\n",
        "Milliseconds = my_cols[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Data"
      ],
      "metadata": {
        "id": "-10IClfXNE8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the data tables to dataframes\n",
        "dfs = []\n",
        "dfsNames = []\n",
        "dfs_vel = []\n",
        "dfs_accel = []\n",
        "i=0\n",
        "\n",
        "for filename in os.listdir(myPath):\n",
        "    if filename.endswith(\"txt\"): \n",
        "        dfs.append(importData(filename, myPath))\n",
        "        dfsNames.append(filename[:-4])\n",
        "        tempData1, tempData2 = generateDerivativeFrames(dfs[i])\n",
        "        dfs_vel.append(tempData1)\n",
        "        dfs_vel.append(tempData2)\n",
        "        i+=1"
      ],
      "metadata": {
        "id": "yW5fAlh9ADJT"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJuFMNe7-ndR"
      },
      "source": [
        "#Graphing & Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqrZPRSM1PyH"
      },
      "source": [
        "##Graph Column or ColPair Section (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "hs-UYpVt1TeE"
      },
      "outputs": [],
      "source": [
        "def GraphColumnsSection(colTitles = [], df = data, xstart = 0, xend = None, together = False):\n",
        "  \"\"\"\n",
        "  graphs the given columns from the given dataframe, with a restricted x axis\n",
        "  colTitles: list, array\n",
        "    a list or array of all names of columns which will be graphed\n",
        "  df: dataframe\n",
        "    the dataframe that the columns will be from\n",
        "  together: boolean\n",
        "    Whether or not the graphs will be overlayed or not\n",
        "  xstart: integer\n",
        "    The lowest value for the x axis\n",
        "  xend: integer\n",
        "    The highest value for the x axis\n",
        "  \"\"\"\n",
        "  # if xend is not input\n",
        "  if xend == None:\n",
        "    # set the maximum x value to the highest it can be with the given dataframe\n",
        "    xend = max(df[Milliseconds])\n",
        "  # if together is True, graph both graphs on the same axis\n",
        "  if together:\n",
        "    fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
        "    for colTitle in colTitles:\n",
        "      ax.plot(df[Milliseconds], df[colTitle], label = colTitle)\n",
        "      ax.legend()\n",
        "      ax.set_xlim(xstart, xend)\n",
        "  # otherwise, graph them on different axes\n",
        "  else:\n",
        "    fig, ax = plt.subplots(len(colTitles), 1, figsize = (8, 6*len(colTitles)))\n",
        "    for i in range(len(colTitles)):\n",
        "      ax[i].plot(df[Milliseconds], df[colTitles[i]], label = colTitles[i])\n",
        "      ax[i].legend()\n",
        "      ax[i].set_xlim(xstart, xend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "hH4MEkUeja8V"
      },
      "outputs": [],
      "source": [
        "def GraphColPairsSection(pairs = [], df = data, xstart = 0, xend = None):\n",
        "  \"\"\"\n",
        "  graphs the given column pairs from the given dataframe, with a restricted x axis\n",
        "  pairs: list, array\n",
        "    a list or array of all names of column pairs which will be graphed\n",
        "  df: dataframe\n",
        "    the dataframe that the columns will be from\n",
        "  xstart: integer\n",
        "    The lowest value for the x axis\n",
        "  xend: integer\n",
        "    The highest value for the x axis\n",
        "  \"\"\"\n",
        "  # if xend is not input\n",
        "  if xend == None:\n",
        "    # set the maximum x value to the highest it can be with the given dataframe\n",
        "    xend = max(df[Milliseconds])\n",
        "  # create figure and axis\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
        "  # graph each pair with the restricted x axis\n",
        "  for pairName in pairs:\n",
        "    colPairs[pairName][0]\n",
        "    ax.plot(df[Milliseconds], df[colPairs[pairName][0]], label = colPairs[pairName][0])\n",
        "    ax.plot(df[Milliseconds], df[colPairs[pairName][1]], label = colPairs[pairName][1])\n",
        "    ax.legend()\n",
        "    ax.set_xlim(xstart, xend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tk2Eadx3wKL"
      },
      "source": [
        "##Graph All (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "AqKm7WrhfSjP"
      },
      "outputs": [],
      "source": [
        "def graphAll(dfs = [], titles = [], skinnyGraph = True, scaled = False):\n",
        "  \"\"\"\n",
        "  graphs all of the columns for each of the given dataframes\n",
        "  the format of the graph depends on the 'skinnyGraph' variable\n",
        "  dfs: list\n",
        "    the list of dataframes which will have thier columns graphed\n",
        "  titles: list\n",
        "    the list of titles corresponding to the dataframes\n",
        "    the first element of titles will be used to label the first element of dfs, etc.\n",
        "  skinnyGraph: boolean\n",
        "    if True, each dataframe will occupy only one column\n",
        "    if False, the graphs will still be next to each other, but will occupy multiple columns\n",
        "  scaled: boolean\n",
        "    if True, the y axis will go from 0 to 1\n",
        "\n",
        "  returns:\n",
        "    the graph of all the columns of each dataframe\n",
        "  \"\"\"\n",
        "  # calculates graph size based on the amount of dataframes input\n",
        "  if skinnyGraph == True:\n",
        "    totalRows = len(dfs[0].columns)-2\n",
        "    totalColumns = len(dfs)\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "  else:\n",
        "    totalGraphsNum = len(dfs)*(len(dfs[0].columns)-2)\n",
        "    totalRows = math.floor(math.sqrt(totalGraphsNum))\n",
        "    totalColumns = math.ceil(totalGraphsNum/totalRows)\n",
        "    while totalColumns % len(dfs) != 0:\n",
        "      totalColumns+=1\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "\n",
        "  # create the figure and axis\n",
        "  fig, ax = plt.subplots(totalRows, totalColumns, figsize = figsize)\n",
        "  # if scaled is true, limit the y axis\n",
        "  if scaled == True:\n",
        "    plt.setp(ax, ylim = (0, 1))\n",
        "  # create the graph and save it to a file\n",
        "  row = 0\n",
        "  column = 0\n",
        "  colTitles = dfs[0].columns[2:]\n",
        "  # if there is more than one column, create the graph via this logic\n",
        "  if totalColumns > 1:\n",
        "    for col in colTitles:\n",
        "      for i in range(0, len(dfs)):\n",
        "        x=dfs[i][Milliseconds]\n",
        "        y=dfs[i][col]\n",
        "\n",
        "        ax[row, column+i].plot(x,y, label=col)\n",
        "        ax[row, column+i].set_title(f'{titles[i]}')\n",
        "        ax[row, column+i].legend()\n",
        "      row+=1\n",
        "      if row%totalRows==0:\n",
        "        row = 0\n",
        "        column+=len(dfs)\n",
        "  # otherwise, use this logic\n",
        "  else:\n",
        "    for col in colTitles:\n",
        "      x=dfs[0][Milliseconds]\n",
        "      y=dfs[0][col]\n",
        "\n",
        "      ax[row].plot(x,y, label=col)\n",
        "      ax[row].set_title(f'{titles[0]}')\n",
        "      ax[row].legend()\n",
        "      row+=1\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "MqO3dcIT65_X"
      },
      "outputs": [],
      "source": [
        "def graphAllToFile(dfs = [], titles = [], skinnyGraph = True, scaled = False):\n",
        "  \"\"\"\n",
        "  graphs all of the columns for each of the given dataframes and outputs them to a file\n",
        "  the format of the graph depends on the 'skinnyGraph' variable\n",
        "  dfs: list\n",
        "    the list of dataframes which will have thier columns graphed\n",
        "  titles: list\n",
        "    the list of titles corresponding to the dataframes\n",
        "    the first element of titles will be used to label the first element of dfs, etc.\n",
        "  skinnyGraph: boolean\n",
        "    if True, each dataframe will occupy only one column\n",
        "    if False, the graphs will still be next to each other, but will occupy multiple columns\n",
        "  scaled: boolean\n",
        "    if True, the y axis will go from 0 to 1\n",
        "  \"\"\"\n",
        "  fig = graphAll(dfs,names)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  saveGraph(fig, f\"{nametotal}All Graphs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1txNAih4csBT"
      },
      "source": [
        "##Fourier Transform Functions (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "YpyMQC6FkoTJ"
      },
      "outputs": [],
      "source": [
        "def compareFourierTransforms(dfs = [], titles = [], skinnyGraph = True):\n",
        "  \"\"\"\n",
        "  outputs graphs of the fourier transforms of each column in the input dataframes\n",
        "  dfs: list\n",
        "    the list of dataframes that will have their columns' fourier transforms compared\n",
        "  titles: list\n",
        "    the names of the corresponding output columns\n",
        "    the 1st name will be attached to the first dataframe, and so on\n",
        "  skinnyGraph: boolean\n",
        "    If true, the graph will have as many columns as dataframes input\n",
        "    If false, the graph will instead be more square-shaped\n",
        "  returns:\n",
        "    a graph with the fourier transforms for each column in the given dataframes\n",
        "  \"\"\"\n",
        "  # seting graph sizes\n",
        "  if skinnyGraph == True:\n",
        "    totalRows = len(my_cols[12:])\n",
        "    totalColumns = len(dfs)\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "  else:\n",
        "    totalGraphsNum = len(dfs)*len(my_cols[12:])\n",
        "    totalRows = math.floor(math.sqrt(totalGraphsNum))\n",
        "    totalColumns = math.ceil(totalGraphsNum/totalRows)\n",
        "    while totalColumns % len(dfs) != 0:\n",
        "       totalColumns+=1\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "\n",
        "  fig, ax = plt.subplots(totalRows, totalColumns, figsize = figsize)\n",
        "\n",
        "  # creating the fourier transforms at their appropriate location in the graph\n",
        "  for i in range(len(dfs)):\n",
        "    for j in range(len(my_cols[12:])):\n",
        "      FFT = np.fft.fft(dfs[i][my_cols[j+12]])\n",
        "      freq = np.arange(len(dfs[i][Milliseconds]))/dfs[i][Milliseconds][len(dfs[i][Milliseconds])-1] # scale by dividing by max time\n",
        "      ax[j][i].plot(freq,np.abs(FFT))\n",
        "      ax[j][i].set_title(f\"{titles[i]}, {my_cols[j+12]}\")\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "F7hyWRE4cupQ"
      },
      "outputs": [],
      "source": [
        "def fourierTransform(df = data):\n",
        "  \"\"\"\n",
        "  displays all graphs for the fourier transforms in a given dataframe\n",
        "  data: dataframe\n",
        "    the dataframe that has columns that will be input into the fourier transform\n",
        "  returns:\n",
        "    multiple graphs, each of a column that has been input into the fourier transform\n",
        "  \"\"\"\n",
        "  for col in my_cols[2:]:\n",
        "    SecondsfromNano = df[Milliseconds]/1000\n",
        "    \n",
        "    FFT = np.fft.fft(df[col])\n",
        "    freq = np.arange(len(SecondsfromNano))/SecondsfromNano[len(SecondsfromNano)-1] # scale by dividing by max time\n",
        "    fig, ax = plt.subplots(1,1, figsize = (10,8))\n",
        "    ax.set_xlim(0, 30)\n",
        "    ax.plot(freq,np.abs(FFT))\n",
        "    ax.set_title(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "bG5kXkwXpDZA"
      },
      "outputs": [],
      "source": [
        "def fourierTransformInterval(df = data, col = \"LE x\", startinit = 0, endinit = 10000, xlim = (0, 30), ylim = None):\n",
        "  \"\"\"\n",
        "  performs a fourier transform on a certain interval for a specific column in a specific dataframe\n",
        "  df: dataframe\n",
        "    the dataframe input\n",
        "  col: string\n",
        "    the name of the column to be input\n",
        "  startinit: integer\n",
        "    the lower bound for the fourier transform\n",
        "  endinit: integer\n",
        "    the higher bound for the fourier transform\n",
        "  xlim: tuple\n",
        "    the bounds for the x-axis\n",
        "  ylim: tuple\n",
        "    the bounds for the y-axis\n",
        "    If not input, the y axis will be automatically assigned\n",
        "  \"\"\"\n",
        "  start = findInDf(startinit, df)\n",
        "  end = findInDf(endinit, df)\n",
        "\n",
        "  SecondsfromNano = df[Milliseconds][start:end]/1000\n",
        "\n",
        "  FFT = np.fft.fft(df[col][start:end])\n",
        "  freq = np.arange(len(SecondsfromNano))/(SecondsfromNano[end-1]-SecondsfromNano[start]) # scale by dividing by max time\n",
        "  fig, ax = plt.subplots(1,1, figsize = (10,8))\n",
        "  ax.set_xlim(xlim)\n",
        "  if ylim != None:\n",
        "    ax.set_ylim(ylim)\n",
        "  ax.plot(freq,np.abs(FFT))\n",
        "  ax.set_title(col)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxpLX_ef_P0V"
      },
      "source": [
        "#Averages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-mIukfvJvIG"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "DlVvdWJwaFB3"
      },
      "outputs": [],
      "source": [
        "def covertValuesToArray(dictionary = colPairs):\n",
        "  propertyColumn = list(dictionary.values())\n",
        "  expandedColumn = []\n",
        "  for i in propertyColumn:\n",
        "    for j in range(2):\n",
        "      expandedColumn.append(i[j])\n",
        "  return expandedColumn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "kd4tIqj8_SC_"
      },
      "outputs": [],
      "source": [
        "def averageData(dataTitle=[Milliseconds]):\n",
        "  \"\"\"\n",
        "  prints the average value of all the entries of a column for each of the given colums in data\n",
        "  dataTitle: list\n",
        "    a list of column names\n",
        "\n",
        "  returns:\n",
        "    none\n",
        "    \n",
        "  example:\n",
        "    averageData([Milliseconds, 'browDown_L'])\n",
        "  \"\"\"\n",
        "  for cols in dataTitle:\n",
        "    #if bs\n",
        "    if cols == my_cols[0]:\n",
        "      cols = Milliseconds\n",
        "      print('Error: Cannot average \\'bs\\'')\n",
        "    print(f\"{cols}: {np.average(data[cols])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "ebC2JVV-nvPA"
      },
      "outputs": [],
      "source": [
        "def findInDf(number=0, df = data):\n",
        "  while True:\n",
        "    try:\n",
        "      start = list(df[Milliseconds]).index(number)\n",
        "      break\n",
        "    except:\n",
        "      number+=1\n",
        "\n",
        "  return start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "yZC88lKowlxw"
      },
      "outputs": [],
      "source": [
        "def averageValuesFrame(dfs = [], names = [],individualColPairs = False):\n",
        "  if individualColPairs == False:\n",
        "    expandedColumn = covertValuesToArray(colPairs)\n",
        "    avgValueFrame = pd.DataFrame(expandedColumn, columns = [\"Blendshapes\"])\n",
        "\n",
        "    for i in range(len(dfs)):\n",
        "      avgValueList = []\n",
        "      for j in expandedColumn:\n",
        "        avgColValue = np.average(dfs[i][j])\n",
        "        avgValueList.append(avgColValue)\n",
        "      avgValueList = pd.Series(avgValueList)\n",
        "      avgValueFrame = pd.concat([avgValueFrame, avgValueList.rename(f\"{names[i]}\")], axis=1)\n",
        "    return avgValueFrame\n",
        "\n",
        "  if individualColPairs == True:\n",
        "    propertyColumn = list(colPairs.keys())\n",
        "    avgValueFrame = pd.DataFrame(propertyColumn, columns = [\"Blendshape Pairs\"])\n",
        "\n",
        "    for i in range(len(dfs)):\n",
        "      avgValueList = []\n",
        "      for j in propertyColumn:\n",
        "        colName1 = colPairs[j][0]\n",
        "        colName2 = colPairs[j][1]\n",
        "\n",
        "        avgColValue1 = np.average(dfs[i][colName1])\n",
        "        avgColValue2 = np.average(dfs[i][colName2])\n",
        "        avgColValue = np.average([avgColValue1, avgColValue2])\n",
        "\n",
        "        avgValueList.append(avgColValue)\n",
        "\n",
        "      avgValueList = pd.Series(avgValueList)\n",
        "      avgValueFrame = pd.concat([avgValueFrame, avgValueList.rename(f\"{names[i]}\")], axis=1)\n",
        "    return avgValueFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Average over an Interval"
      ],
      "metadata": {
        "id": "qB_ZakvtOXjC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "DmxdgJZDDloo"
      },
      "outputs": [],
      "source": [
        "def averageDataInterval(dataTitle=[Milliseconds], start=0, end=3000):\n",
        "  \"\"\"\n",
        "  prints the average of the values for each of the given columns over the given interval\n",
        "  dataTitle: list\n",
        "    a list of strings that are column names\n",
        "  start: int\n",
        "    the starting number in Milliseconds to begin averaging points at\n",
        "  end: int\n",
        "    the ending number in Milliseconds to begin averaging points at\n",
        "  \n",
        "  returns:\n",
        "    none\n",
        "    \n",
        "  example:\n",
        "    averageDataInterval([Milliseconds, 'browDown_L'], 0, 2000)\n",
        "  \"\"\"\n",
        "  # out of bounds error checking\n",
        "  if start>3008 or start<0 or end>3008 or start>=end:\n",
        "    print('Error: Out of Bounds')\n",
        "    return None\n",
        "\n",
        "  # correct starting values in Milliseconds\n",
        "  start = findInDf(start, data)\n",
        "  end = findInDf(end, data)\n",
        "  # print interval range\n",
        "  print(f\"Averages over the interval [{data[Milliseconds][start]}, {data[Milliseconds][end]}]:\")\n",
        "  # for each column calculate and print averages\n",
        "  for cols in dataTitle:\n",
        "    #bs column error checking\n",
        "    if cols == my_cols[0]:\n",
        "      cols = Milliseconds\n",
        "      print('Error: Cannot average \\'bs\\'')\n",
        "    # calculate and print average value for a given column\n",
        "    averageOverInterval = np.average(data[cols][start:end])\n",
        "    print(f\"{cols}: {averageOverInterval}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKFmU4XdwlZz"
      },
      "source": [
        "##Average To File (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "MZVsDFcycYcc"
      },
      "outputs": [],
      "source": [
        "def averageValuesToFile(dfs = [], names = [], individualColPairs = False):\n",
        "  \"\"\"\n",
        "  outputs the average values of the given dataframes to a file\n",
        "  \"\"\"\n",
        "  avgValuesFrame = averageValuesFrame(dfs, names, individualColPairs)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  avgValuesFrame.to_csv(f\"{outputPath}/{nametotal}Average Values.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSATt-PKXDzD"
      },
      "source": [
        "#Symmetry Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRhAOkpMC7K0"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "dHsXUgPBSD99"
      },
      "outputs": [],
      "source": [
        "zFillValue = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "l5JgKcCUFabT"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleys(dataTitle, ax):\n",
        "  \"\"\"\n",
        "  creates a list of all points in data where each point is equal to the points adjacent to it\n",
        "  dataTitle: string\n",
        "    the name of a column in data\n",
        "  ax:\n",
        "    the axis of a given graph\n",
        "    multiple axis elements are stored as an np.ndarray\n",
        "\n",
        "  returns:\n",
        "    a list of points, where each point is equal to the points adjacent to it\n",
        "  \"\"\"\n",
        "  pav = []\n",
        "  # if ax is a list, set it to its first graph\n",
        "  if type(ax) is np.ndarray:\n",
        "    ax = ax[0]\n",
        "  # for each point in the given column\n",
        "  for n in range(1, len(data[dataTitle])-1):\n",
        "    # if this point is increaseing, color it red\n",
        "    if data[dataTitle][n-1] < data[dataTitle][n] and data[dataTitle][n] < data[dataTitle][n+1]:\n",
        "      ax.scatter(data[Milliseconds][n], data[dataTitle][n], color = 'Red')\n",
        "      pass\n",
        "    # if this point is decreasing, color it green\n",
        "    elif data[dataTitle][n-1] > data[dataTitle][n] and data[dataTitle][n] > data[dataTitle][n+1]:\n",
        "      ax.scatter(data[Milliseconds][n], data[dataTitle][n], color = 'Green')\n",
        "      pass\n",
        "    # if this graph is neither increasing nor decreasing, append it to pav\n",
        "    else:\n",
        "      pav.append((data[Milliseconds][n], data[dataTitle][n]))\n",
        "  # color all points in pav black\n",
        "  for n in pav:\n",
        "    ax.scatter(n[0], n[1], color = 'Black')\n",
        "  return pav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "UfYjb_NX5lxk"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysDF(dataTitle, df, ax = None, displaygraph = False):\n",
        "  \"\"\"\n",
        "  creates a list of all points in data where each point is equal to the points adjacent to it\n",
        "  dataTitle: string\n",
        "    the name of a column in data\n",
        "  ax:\n",
        "    the axis of a given graph\n",
        "    multiple axis elements are stored as an np.ndarray\n",
        "\n",
        "  returns:\n",
        "    a list of points, where each point is equal to the points adjacent to it\n",
        "  \"\"\"\n",
        "  pav = []\n",
        "  # if ax is a list, set it to its first graph\n",
        "  if type(ax) is np.ndarray:\n",
        "    ax = ax[0]\n",
        "  # for each point in the given column\n",
        "  for n in range(1, len(df[dataTitle])-1):\n",
        "    # if this point is increaseing, color it red\n",
        "    if df[dataTitle][n-1] < df[dataTitle][n] and df[dataTitle][n] < df[dataTitle][n+1]:\n",
        "      if displaygraph == True:\n",
        "        ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Red')\n",
        "      else:\n",
        "        pass\n",
        "    # if this point is decreasing, color it green\n",
        "    elif df[dataTitle][n-1] > df[dataTitle][n] and df[dataTitle][n] > df[dataTitle][n+1]:\n",
        "      if displaygraph == True:\n",
        "        ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Green')\n",
        "      else:\n",
        "        pass\n",
        "    # if this graph is neither increasing nor decreasing, append it to pav\n",
        "    else:\n",
        "      pav.append((df[Milliseconds][n], df[dataTitle][n]))\n",
        "  # color all points in pav black\n",
        "  if displaygraph == True:\n",
        "    # add the graph line to the graph\n",
        "    ax.plot(df[Milliseconds], df[dataTitle], zorder = 0, label = dataTitle)\n",
        "    for n in pav:\n",
        "      ax.scatter(n[0], n[1], color = 'Black')\n",
        "    ax.legend()\n",
        "    return ax\n",
        "  if displaygraph == False:\n",
        "    return pav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "T7WmzSzXHJD-"
      },
      "outputs": [],
      "source": [
        "def createPavFrame(dataTitle, pav):\n",
        "  \"\"\"\n",
        "  creates a DataFrame that has all of the peaks and valleys in pav, one peak or valley for each column\n",
        "  dataTitle: string\n",
        "    the name of a column in data\n",
        "  pav:\n",
        "    the output of the pav function for the given dataTitle\n",
        "\n",
        "  returns:\n",
        "    a DataFrame that has all of the peaks and valleys in pav, one peak or valley for each column\n",
        "  \"\"\"\n",
        "  pavFrame = pd.DataFrame()\n",
        "\n",
        "  skipValue = (max(data[dataTitle])-min(data[dataTitle]))/8\n",
        "  i = 0\n",
        "  tpoint = 0\n",
        "  for n in range(len(pav)-1):\n",
        "    index = findInDf(pav[n][0], data)\n",
        "    index2 = findInDf(pav[n+1][0], data)\n",
        "    if abs(data[dataTitle][index] - data[dataTitle][index2]) > skipValue or n==len(pav)-3:\n",
        "      j = n+1\n",
        "      ser = pd.Series(pav[i:j], name=f\"Peak/Valley {str(tpoint).zfill(zFillValue)}\")\n",
        "      tpoint=tpoint+1\n",
        "      pavFrame = pd.concat([pavFrame, ser], axis=1)\n",
        "      i = j\n",
        "  \n",
        "  return pavFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Ws5B-2GXJys3"
      },
      "outputs": [],
      "source": [
        "def tupleFixer(column):\n",
        "  \"\"\"\n",
        "  creates an array with one-element entries\n",
        "  dataTitle: string\n",
        "    the name of a column in data\n",
        "  ax:\n",
        "    the axis of a given graph\n",
        "    multiple axis elements are stored as an np.ndarray\n",
        "\n",
        "  returns:\n",
        "    an array that is the same as the input column, but replaces all tuples with only their x-value\n",
        "  \"\"\"\n",
        "  new = []\n",
        "  for x in column:\n",
        "    if x is np.nan:\n",
        "      new.append(x)\n",
        "    else:\n",
        "      new.append(x[0])\n",
        "  new = np.array(new)\n",
        "  return new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "MxWtU2RN9hCn"
      },
      "outputs": [],
      "source": [
        "def pavMidpoint(column):\n",
        "  \"\"\"\n",
        "  finds the x-value of the midpoint of a given column\n",
        "  dataTitle: string\n",
        "    the name of a column in data\n",
        "\n",
        "  returns:\n",
        "    the x-value of the midpoint of a given column\n",
        "  \"\"\"\n",
        "  new = tupleFixer(column)\n",
        "\n",
        "  midPoint = np.nanmedian(new)\n",
        "  #if even number of elements, takes the lower of the two middle values\n",
        "  midPoint = new[new<=midPoint].max()\n",
        "\n",
        "  return midPoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "eNNsh4ZUBUh6"
      },
      "outputs": [],
      "source": [
        "def symmetryValue(column, dataTitle, checkRange=10):\n",
        "  \"\"\"\n",
        "  assigns a value to quantify the symmetry of a given dataTitle\n",
        "  column:\n",
        "    a column in a given pavFrame\n",
        "  dataTitle: string\n",
        "    the name of a column in data\n",
        "  checkRange:\n",
        "    the amount of points to the left and right that the function should search\n",
        "\n",
        "  returns:\n",
        "    returns a value to quantify the symmetry of a given dataTitle\n",
        "  \"\"\"\n",
        "  midPointX = pavMidpoint(column)\n",
        "  midPointIndex = findInDf(midPointX, data)\n",
        "  midPointY = data[dataTitle][midPointIndex]\n",
        "\n",
        "  symmetryRange = data[dataTitle][midPointIndex-checkRange:midPointIndex+checkRange+1]\n",
        "\n",
        "  rightSideInc = None\n",
        "  leftSideInc = None\n",
        "  n = 1\n",
        "\n",
        "  while rightSideInc == None or leftSideInc == None and n<=checkRange+1:\n",
        "    if symmetryRange[midPointIndex] < symmetryRange[midPointIndex+n]:\n",
        "      rightSideInc = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex] > symmetryRange[midPointIndex+n]:\n",
        "      rightSideInc = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex] == symmetryRange[midPointIndex+n]:\n",
        "      rightSideInc = None\n",
        "    if symmetryRange[midPointIndex] < symmetryRange[midPointIndex-n]:\n",
        "      leftSideInc = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex] > symmetryRange[midPointIndex-n]:\n",
        "      leftSideInc = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex] == symmetryRange[midPointIndex-n]:\n",
        "      leftSideInc = None\n",
        "    n+=1\n",
        "\n",
        "  for n in range(2, checkRange):\n",
        "    if symmetryRange[midPointIndex+n-1] < symmetryRange[midPointIndex+n]:\n",
        "      currentChange = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex+n-1] > symmetryRange[midPointIndex+n]:\n",
        "      currentChange = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex+n-1] == symmetryRange[midPointIndex+n]:\n",
        "      currentChange = rightSideInc\n",
        "    if currentChange != rightSideInc:\n",
        "      checkRange = n-1\n",
        "      break\n",
        "    if symmetryRange[midPointIndex-n+1] < symmetryRange[midPointIndex-n]:\n",
        "      currentChange = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex-n+1] > symmetryRange[midPointIndex-n]:\n",
        "      currentChange = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex-n+1] == symmetryRange[midPointIndex-n]:\n",
        "      currentChange = leftSideInc\n",
        "    if currentChange != leftSideInc and n-1 <= checkRange:\n",
        "      checkRange = n-1\n",
        "      break\n",
        "\n",
        "  symmetryRangeNew = data[dataTitle][midPointIndex-checkRange:midPointIndex+checkRange+1]\n",
        "\n",
        "  symmetryNumbers = []\n",
        "  for n in range(1,checkRange+1):\n",
        "    x = abs(symmetryRangeNew[midPointIndex]-symmetryRangeNew[midPointIndex-n])\n",
        "    symmetryNumbers.append(x)\n",
        "    x = abs(symmetryRangeNew[midPointIndex+n]-symmetryRangeNew[midPointIndex])\n",
        "    symmetryNumbers.append(x)\n",
        "  return np.mean(symmetryNumbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "bzrq7AUWGAVc"
      },
      "outputs": [],
      "source": [
        "def symmetryValuesPosition(dataTitle, df = data):\n",
        "  tempSymmetryValues = []\n",
        "  for i, j in zip(df[dataTitle[0]], df[dataTitle[1]]):\n",
        "    if i+j==0:\n",
        "      tempSymmetryValues.append(0)\n",
        "    else:\n",
        "      tempSymmetryValues.append(np.round(abs((j-i)/((i+j)/2)), 4))\n",
        "  return np.mean(tempSymmetryValues)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "3cZc_5xfudf9"
      },
      "outputs": [],
      "source": [
        "def allSymmetry(dfs = [data]):\n",
        "  for i in dfs:\n",
        "    allSymmArr = []\n",
        "    for key, value in colPairs.items():\n",
        "      allSymmArr.append(np.round(100*compareSymmetryPosition(value, i), 2))\n",
        "    for n, key in zip(range(len(colPairs.keys())),colPairs.keys()):\n",
        "      compareSymmetryPosition(colPairs[key], i)\n",
        "      print(f\"{key}: {allSymmArr[n]}\")\n",
        "    print(f\"Mean average value: {np.round(np.mean(allSymmArr), 2)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2k6x407L04u"
      },
      "source": [
        "##AnalyzeSymmetry Function\n",
        "A function that shows the peaks and valleys of a column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "caxdbWitXIRv"
      },
      "outputs": [],
      "source": [
        "def analyzeSymmetry(dataTitle='jawForward'):\n",
        "  \"\"\"\n",
        "  creates and displays a dictionary for the peaks and valleys of data, where\n",
        "  the key is the peak number in the format 'Peak/Valley XXX', and the value is\n",
        "  a list with the x-value of where the peak or valley appears and the \n",
        "  symmetry value for that peak or valley\n",
        "  dataTitle:\n",
        "    the column in data which is analyzed\n",
        "\n",
        "  returns:\n",
        "    none, displays dictionary of peaks and valleys and a graph that shows\n",
        "    which points are increasing, which remain the same, and which ones are decreasing\n",
        "  \"\"\"\n",
        "\n",
        "  #graphing\n",
        "  fig, ax = graphPlotData([dataTitle], False, False)\n",
        "\n",
        "  #creating pav AND adding the graphical dots\n",
        "  pav = peaksAndValleys(dataTitle, ax)\n",
        "\n",
        "  #creating & populating pavFrame\n",
        "  pavFrame = createPavFrame(dataTitle, pav)\n",
        "\n",
        "  #creating pavdict\n",
        "  pavDict = {}\n",
        "  # for each peak or valley\n",
        "  for n in range(len(pavFrame.columns)):\n",
        "    # create a string that is 3 characters long, consisting of left zeros in empty places\n",
        "    # this string will be the title of the corresponding peak or valley midpoint\n",
        "    sortedN = str(n).zfill(zFillValue)\n",
        "    #establish title\n",
        "    titleOfPoint=f\"Peak/Valley {sortedN}\"\n",
        "    # find the midpoint of the entries in the given column of pavFrame, converted to int\n",
        "    midpointOfPavFrameColumn = int(pavMidpoint(pavFrame[titleOfPoint]))\n",
        "    # finding the symmetry value that corresponds to dataTitle in data\n",
        "    # then, round the symmetry value to 4 decimal places\n",
        "    dataTitleSymmetryValue = symmetryValue(pavFrame[titleOfPoint], dataTitle)\n",
        "    dataTitleSymmetryValueRounded = np.round(dataTitleSymmetryValue, 4)\n",
        "    # create an entry in pavDict with a title \"titleofPoint\" that corresponds to (x, symmetry)\n",
        "    # where x is the time value for the midpoint of given peak/valley\n",
        "    # where symmetry is the symmetry value for the given peak/valley\n",
        "    pavDict[titleOfPoint] = [midpointOfPavFrameColumn, dataTitleSymmetryValueRounded]\n",
        "  \n",
        "  display(pavDict)\n",
        "# ---------------------------------------------------------------------------------\n",
        "# analyzeSymmetry('jawForward')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqFkhYhvULA9"
      },
      "source": [
        "#Symmetry Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUfp5VXXJhAc"
      },
      "source": [
        "##Compare Symmetry Graph Functions\n",
        "Functions that display graphs of columns of the data sets for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "tLYKzWpqYAvb"
      },
      "outputs": [],
      "source": [
        "def compareSymmetryGraphs(dfs = [], titles = [], skinnyGraph = True, scaled = False):\n",
        "  if skinnyGraph == True:\n",
        "    totalRows, totalColumns, figsize = skinnyGraphSizes(dfs)\n",
        "  else:\n",
        "    totalRows, totalColumns, figsize = squareGraphSizes(dfs)\n",
        "\n",
        "  fig, ax = plt.subplots(totalRows, totalColumns, figsize = figsize)\n",
        "  \n",
        "  if scaled == True:\n",
        "    plt.setp(ax, ylim = (0, 1))\n",
        "\n",
        "  graphColPair(dfs, titles, colPairs.keys(), ax, totalRows)\n",
        "  display(fig)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHIilKasTJs5"
      },
      "source": [
        "## Symmetry Values Functions\n",
        "Functions that the symmetry values for comparison between two parts of a colPair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "qBH-O1vuZkb8"
      },
      "outputs": [],
      "source": [
        "def symmetryValues(dfs = [], names = []):\n",
        "  propertyColumn = list(colPairs.keys())\n",
        "  symmValueFrame = pd.DataFrame(propertyColumn, columns = [\"Blendshapes\"])\n",
        "\n",
        "  for i in range(len(dfs)):\n",
        "    symmValueList = []\n",
        "    for key in colPairs.keys():\n",
        "      col1 = dfs[i][colPairs[key][0]]\n",
        "      col2 = dfs[i][colPairs[key][1]]\n",
        "      symmValue = getSymmetryValue(col1, col2)\n",
        "      symmValueList.append(symmValue)\n",
        "    symmValueList = pd.Series(symmValueList)\n",
        "    symmValueFrame = pd.concat([symmValueFrame, symmValueList.rename(f\"{names[i]}\")], axis=1)\n",
        "  return symmValueFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye8zj_KmIqEt"
      },
      "source": [
        "##ToFile Functions (FINAL)\n",
        "Functions that create an output file for graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "FW7t9Jy_EzPJ"
      },
      "outputs": [],
      "source": [
        "def compareSymmetryGraphsToFile(dfs = [], titles = [], skinnyGraph = True, scaled = False):\n",
        "  fig = compareSymmetryGraphs(dfs, titles, skinnyGraph, scaled)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  saveGraph(fig, f\"{nametotal}Symmetry Graph\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "7EDPLFXvhLHv"
      },
      "outputs": [],
      "source": [
        "def symmetryValuesToFile(dfs = [], names = []):\n",
        "  symmValueFrame = symmetryValues(dfs, names)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  symmValueFrame.to_csv(f\"{outputPath}/{nametotal}Symmetry Values.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzQ2Od3ESJ7z"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "8KBqiXYcY3rF"
      },
      "outputs": [],
      "source": [
        "def getSymmetryValue(y1, y2):\n",
        "  tempSymmetryValues = []\n",
        "  for i, j in zip(y1, y2):\n",
        "    if i+j==0:\n",
        "      tempSymmetryValues.append(0)\n",
        "    else:\n",
        "      difference = abs((j-i))\n",
        "      tempSymmetryValues.append(difference)\n",
        "  averageSymmetryValue = np.mean(tempSymmetryValues)\n",
        "  return np.round(averageSymmetryValue, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "aeNLGNlGT5p-"
      },
      "outputs": [],
      "source": [
        "def skinnyGraphSizes(dfs = []): \n",
        "  totalRows = len(colPairs.keys())\n",
        "  totalColumns = len(dfs)\n",
        "  figsize=(8*totalColumns, 6*totalRows)\n",
        "  return totalRows, totalColumns, figsize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "wbgVl_gZS9U2"
      },
      "outputs": [],
      "source": [
        "def squareGraphSizes(dfs = []):\n",
        "  totalGraphsNum = len(dfs)*len(colPairs.keys())\n",
        "  totalRows = math.floor(math.sqrt(totalGraphsNum))\n",
        "  totalColumns = math.ceil(totalGraphsNum/totalRows)\n",
        "  while totalColumns % len(dfs) != 0:\n",
        "      totalColumns+=1\n",
        "  figsize=(8*totalColumns, 6*totalRows)\n",
        "  return totalRows, totalColumns, figsize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "EZF-RNXWPfWq"
      },
      "outputs": [],
      "source": [
        "def saveGraph(fig, name):\n",
        "  fileName = f'{outputPath}/{name}.png'\n",
        "  fig.savefig(fileName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "8rmQS_gtKZoP"
      },
      "outputs": [],
      "source": [
        "def graphColPair(dfs = [], titles = [],keys = [], ax = \"Placeholder\", totalRows = 5):\n",
        "  row = 0\n",
        "  column = 0\n",
        "\n",
        "  for key in keys:\n",
        "    for i in range(len(dfs)):\n",
        "      colTitles = colPairs[key]\n",
        "      x1=dfs[i][Milliseconds]\n",
        "      y11=dfs[i][colTitles[0]]\n",
        "      y12=dfs[i][colTitles[1]]\n",
        "\n",
        "      ax[row, column+i].plot(x1,y11, label=colTitles[0])\n",
        "      ax[row, column+i].plot(x1,y12, label=colTitles[1])\n",
        "      ax[row, column+i].set_title(f'{titles[i]}')\n",
        "      ax[row, column+i].legend()\n",
        "    row+=1\n",
        "    if row%totalRows==0:\n",
        "      row = 0\n",
        "      column+=len(dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxdv47_6_i9J"
      },
      "source": [
        "#Eye Blink Counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwubzESWHn5I"
      },
      "source": [
        "##Count Blinks & Blinks per Second (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "N5WV8YFX_nJp"
      },
      "outputs": [],
      "source": [
        "def CountBlinks(df = data, tolerance = 0.1, middlePointMax = 10, name = \"\"):\n",
        "  \"\"\"\n",
        "  counts the amount of blinks in the given dataframe\n",
        "  does this my counting the amount of times that there is a low point followed by a high point\n",
        "  a low point is any point that is lower than \"tolerance\" of the midpoint\n",
        "  a high point is any point that is higher than \"tolerance\" of the midpoint\n",
        "  ex. if the average y value is 0.4:\n",
        "      any point with a y value lower than 0.2 would be a low point\n",
        "      any point with a y value higher than 0.6 would be a high point\n",
        "  if there are more than \"midpoint\" points within \"tolerance\" of the middle\n",
        "  the dataset must be manually reviewed, as the blink number would be innacurate\n",
        "\n",
        "  returns:\n",
        "  The amount of blinks and blinks per second for the given dataframe\n",
        "  \"\"\"\n",
        "  middlePoints = 0\n",
        "  pav_L = peaksAndValleysDF(\"eyeBlink_L\", df)\n",
        "  pav_R = peaksAndValleysDF(\"eyeBlink_R\", df)\n",
        "  pav = [pav_L, pav_R]\n",
        "\n",
        "  if name != \"\":\n",
        "    name+=\": \"\n",
        "\n",
        "  for i in range(len(pav)):\n",
        "    highestPav = max(pav[i], key=itemgetter(1))[1]\n",
        "    lowestPav = min(pav[i], key=itemgetter(1))[1]\n",
        "\n",
        "    mediumvalue = (highestPav+lowestPav)/2\n",
        "    lowbound = mediumvalue-tolerance\n",
        "    highbound = mediumvalue+tolerance\n",
        "\n",
        "    for j in pav[i]:\n",
        "      if j[1] > lowbound and j[1] < highbound:\n",
        "        middlePoints+=1\n",
        "    if middlePoints>=middlePointMax:\n",
        "      if i == 0:\n",
        "        LorR = \"L\"\n",
        "      if i == 1:\n",
        "        LorR = \"R\"\n",
        "      print(f\"{name}Please review eyeBlink_{LorR} Manually\")\n",
        "    else:\n",
        "      blinks = 0\n",
        "      seconds = max(df[Milliseconds])/1000\n",
        "\n",
        "      point0 = 0\n",
        "      point1 = 1\n",
        "      for y in pav[i][:-1]:\n",
        "        y1 = pav[i][point0][1]\n",
        "        y2 = pav[i][point1][1]\n",
        "        if y1 < lowbound and y2 > highbound:\n",
        "          blinks+=1\n",
        "        point0+=1\n",
        "        point1+=1\n",
        "\n",
        "      bps = blinks/seconds\n",
        "      if i == 0:\n",
        "        LorR = \"L\"\n",
        "      if i == 1:\n",
        "        LorR = \"R\"\n",
        "      print(f\"{name}eyeBlink_{LorR} has {blinks} blinks, for a total of {bps} blinks per second.\")\n",
        "  # return mediumvalue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "FH4ux24oB-CG"
      },
      "outputs": [],
      "source": [
        "def showBlinkGraphs(df = data):\n",
        "  \"\"\"\n",
        "  Graphs the eyeBlink blendshapes for the given dataframe.\n",
        "  If the point has a positive slope, it is red\n",
        "  If the point has a negative slope, it is green\n",
        "  Otherwise, it is black\n",
        "  df: dataframe\n",
        "    the dataframe of which to graph the blink blendshapes\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(2, 1, figsize = (8, 12))\n",
        "  peaksAndValleysGraph(\"eyeBlink_L\", df, fig, ax[0])\n",
        "  peaksAndValleysGraph(\"eyeBlink_R\", df, fig, ax[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Blink Graphs To File (FINAL)\n"
      ],
      "metadata": {
        "id": "LeDtNPFrnJmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BlinkGraphsToFile(dfs = [], names = []):\n",
        "  \"\"\"\n",
        "  Graphs the eyeBlink blendshapes for the given dataframes and returns them in a file\n",
        "  If the point has a positive slope, it is red\n",
        "  If the point has a negative slope, it is green\n",
        "  Otherwise, it is black\n",
        "  df: dataframe\n",
        "    the dataframe of which to graph the blink blendshapes\n",
        "  \"\"\"\n",
        "  for i in range(len(dfs)):\n",
        "    fig, ax = plt.subplots(2, 1, figsize = (8, 12))\n",
        "    peaksAndValleysGraph(\"eyeBlink_L\", dfs[i], fig, ax[0])\n",
        "    ax[0].set_title(\"eyeBlink_L\")\n",
        "    peaksAndValleysGraph(\"eyeBlink_R\", dfs[i], fig, ax[1])\n",
        "    ax[1].set_title(\"eyeBlink_R\")\n",
        "    saveGraph(fig, f\"{names[i]} Blink Graphs\")"
      ],
      "metadata": {
        "id": "dybk4MUrnDF4"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th8kESrrAp4m"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def peaksAndValleysGraph(dataTitle, df, fig = None, ax = None):\n",
        "  \"\"\"\n",
        "  visualizes on a graph which points in the given column of df are the decreasing, incraesing, or neither\n",
        "  dataTitle: string\n",
        "    the column to graph\n",
        "  df: dataframe\n",
        "    the dataframe from which to graph the column\n",
        "  ax: axis\n",
        "    the axis to graph on\n",
        "  \"\"\"\n",
        "  if fig == None or ax == None:\n",
        "    fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
        "  ax.plot(df[Milliseconds],df[dataTitle],zorder = -1)\n",
        "  # for each point in the given column\n",
        "  for n in range(1, len(df[dataTitle])-1):\n",
        "    # if this point is increasing, color it red\n",
        "    if df[dataTitle][n-1] < df[dataTitle][n] and df[dataTitle][n] < df[dataTitle][n+1]:\n",
        "      ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Red')\n",
        "      pass\n",
        "    # if this point is decreasing, color it green\n",
        "    elif df[dataTitle][n-1] > df[dataTitle][n] and df[dataTitle][n] > df[dataTitle][n+1]:\n",
        "      ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Green')\n",
        "      pass\n",
        "    # if this graph is neither increasing nor decreasing, color it black\n",
        "    else:\n",
        "      ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Black')"
      ],
      "metadata": {
        "id": "4FNS3FuMht-z"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "3-VA57ZvAPjj"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysDF(dataTitle, df):\n",
        "  \"\"\"\n",
        "  creates a list of all points in the given dataframe where each point is equal to the points adjacent to it\n",
        "  dataTitle: string\n",
        "    the name of a column in the dataframe\n",
        "  df: dataframe\n",
        "    the dataframe to draw from\n",
        "\n",
        "  returns:\n",
        "    a list of points, where each point is equal to the points adjacent to it\n",
        "  \"\"\"\n",
        "  pav = []\n",
        "  # for each point in the given column\n",
        "  for n in range(1, len(df[dataTitle])-1):\n",
        "    # if this point is increaseing, do nothing\n",
        "    if df[dataTitle][n-1] < df[dataTitle][n] and df[dataTitle][n] < df[dataTitle][n+1]:\n",
        "      pass\n",
        "    # if this point is decreasing, do nothing\n",
        "    elif df[dataTitle][n-1] > df[dataTitle][n] and df[dataTitle][n] > df[dataTitle][n+1]:\n",
        "      pass\n",
        "    # if this graph is neither increasing nor decreasing (it is a peak or valley), append it to pav\n",
        "    else:\n",
        "      pav.append((df[Milliseconds][n], df[dataTitle][n]))\n",
        "  return pav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSFn9fmItV_0"
      },
      "source": [
        "#Difference Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNgxlirbxmm8"
      },
      "source": [
        "##General Difference Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "2_KwCrKAtY9Y"
      },
      "outputs": [],
      "source": [
        "def difference(df1, colTitle1, colTitle2):\n",
        "  totalgraphs = 3\n",
        "  y1 = df1[colTitle1]\n",
        "  y2 = df1[colTitle2]\n",
        "  y3 = y1-y2\n",
        "  fig, ax = plt.subplots(totalgraphs, 1, figsize = (8, 6*totalgraphs))\n",
        "  ax[0].plot(df1[Milliseconds],y1, label = f\"{colTitle1}\")\n",
        "  ax[1].plot(df1[Milliseconds],y2, label = f\"{colTitle2}\")\n",
        "  ax[2].plot(df1[Milliseconds],y3, label = f\"Difference between {colTitle1} and {colTitle2}\")\n",
        "  for i in range (0,2):\n",
        "    ax[i].legend()\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "vBY4rhnsvxg0"
      },
      "outputs": [],
      "source": [
        "def differenceToFile(df1, colTitle1, colTitle2):\n",
        "  fig = difference(df1, colTitle1, colTitle2)\n",
        "  saveGraph(fig, f\"Difference between {colTitle1} and {colTitle2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51td5Ncwxow8"
      },
      "source": [
        "##Eye Difference Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eyeDifference(dfs=[], names=[], scaledDifference = False):\n",
        "  \"\"\"\n",
        "  outputs graphs of the Left Eye and Right Eye x- and y- eulerAngles\n",
        "  dfs: list\n",
        "    the dataframes for data to be drawn from\n",
        "  scaledDifference: boolean\n",
        "    whether or not the y bounds will be the same for both graphs\n",
        "\n",
        "  returns: graphs of the Left Eye and Right Eye x- and y- eulerAngles\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(3, 2*len(dfs), figsize = (8*2*len(dfs), 6*3))\n",
        "\n",
        "  for q in range(len(dfs)):\n",
        "    for i in range(0+2*q,2+2*q):\n",
        "      if i == 0:\n",
        "        colTitle1 = \"LE x\"\n",
        "        colTitle2 = \"RE x\"\n",
        "      if i == 1:\n",
        "        colTitle1 = \"LE y\"\n",
        "        colTitle2 = \"RE y\"\n",
        "\n",
        "      y1 = dfs[q][colTitle1]\n",
        "      y2 = dfs[q][colTitle2]\n",
        "      y3 = y1-y2\n",
        "      ax[0,i].plot(dfs[q][Milliseconds],y1, label = f\"{colTitle1}\")\n",
        "      ax[1,i].plot(dfs[q][Milliseconds],y2, label = f\"{colTitle2}\")\n",
        "      ax[2,i].plot(dfs[q][Milliseconds],y3, label = f\"{colTitle1} - {colTitle2}\")\n",
        "      for j in range(0,3):\n",
        "        if j == 0 or j == 1:\n",
        "          ax[j,i].set_ylim(-30, 30)\n",
        "        ax[j,i].legend()\n",
        "        ax[j,i].set_title(names[q])\n",
        "\n",
        "    if scaledDifference == True:\n",
        "      ymin0, ymax0 = ax[2,0].get_ylim()\n",
        "      ymin1, ymax1 = ax[2,1].get_ylim()\n",
        "      if ymin1 < ymin0:\n",
        "        ymin = ymin1\n",
        "      if ymin1 > ymin0:\n",
        "        ymin = ymin0\n",
        "      if ymax1 < ymax0:\n",
        "        ymax = ymax0\n",
        "      if ymax1 > ymax0:\n",
        "        ymax = ymax1\n",
        "      ax[2,0].set_ylim(ymin, ymax)\n",
        "      ax[2,1].set_ylim(ymin, ymax)\n",
        "  return fig"
      ],
      "metadata": {
        "id": "UmDmdvvcrfjJ"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "pHj-3XBRyaZk"
      },
      "outputs": [],
      "source": [
        "def eyeDifferenceToFile(dfs = [], names = [], scaledDifference = False):\n",
        "  fig = eyeDifference(dfs, names, scaledDifference)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  saveGraph(fig, f\"{nametotal}LE-RE Difference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUO92M6HG2mW"
      },
      "source": [
        "#End Function (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "yGBr92XIG64I"
      },
      "outputs": [],
      "source": [
        "def outputAllDataAnalysis(dfs = [], names = [], skinnyGraph = True, scaled = True, individualColPairs = False, scaledDifference = False):\n",
        "  symmetryValuesToFile(dfs, names)\n",
        "  averageValuesToFile(dfs, names, individualColPairs)\n",
        "  graphAllToFile(dfs, names, True, False)\n",
        "  eyeDifferenceToFile(dfs, names, scaledDifference)\n",
        "  BlinkGraphsToFile(dfs, names)\n",
        "  if len(dfs) > 1:\n",
        "    compareSymmetryGraphsToFile(dfs, names, skinnyGraph, scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Running Functions"
      ],
      "metadata": {
        "id": "BybkKrM5Nu14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What each function does, basically\n",
        "\n",
        "For specific information, refer to the specific function in the Table of Context"
      ],
      "metadata": {
        "id": "2tbbvYyTN5_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "ywR8QPbt5kJ_"
      },
      "outputs": [],
      "source": [
        "outputAllDataAnalysis(dfs, dfsNames, True, False, False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you want to zoom in on a graph, you can enable or disable zooming by\n",
        "# uncommenting one of the lines below and running this cell\n",
        "# Enable Zoom:\n",
        "# mpld3.enable_notebook()\n",
        "# Disable Zoom:\n",
        "# mpld3.disable_notebook()"
      ],
      "metadata": {
        "id": "edohocOoPPh7"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# commented functions\n",
        "# \"if you want to run a specific function, uncomment the line of the function you want to run,\n",
        "# and specify the inputs of the function\""
      ],
      "metadata": {
        "id": "8oHHJo_UOZSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5B0OoZubwSh7",
        "qIeDknEwFL5m",
        "eJuFMNe7-ndR",
        "nqrZPRSM1PyH",
        "2tk2Eadx3wKL",
        "1txNAih4csBT",
        "GxpLX_ef_P0V",
        "WSATt-PKXDzD",
        "YqFkhYhvULA9",
        "Jxdv47_6_i9J",
        "zSFn9fmItV_0"
      ],
      "name": "FacialDataProject.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1sQahL-K5DcMqxBymblCXkXXkwvWdVFRq",
      "authorship_tag": "ABX9TyPNKmm0wVRt1uINrKtRspSB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}