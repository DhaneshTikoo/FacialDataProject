{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhaneshTikoo/FacialDataProject/blob/main/FacialDataProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blFMC-m0-ZsD"
      },
      "source": [
        "#How to Use\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn70D0Swwoa1"
      },
      "source": [
        "To obtain a Facial Data file, perform the follwing steps:\n",
        "1. If viewing this on Github, click the \"Open in Colab\" button just above.\n",
        "2. Download the app \"Face Cap - Motion Capture\" by FBX Facial motion capture on your iPhone.\n",
        "3. to begin a face recording, Open the app and press \"Record\"\n",
        "4. After approximately 1 minute, end the face recording by pressing the Record button once again.\n",
        "5. Press the \"Export\" button to export the Facial Data file to the Files app on your iPhone.\n",
        "6. In your Google Drive, make a folder called \"Facial Data\"\n",
        "7. Move the Facial Data file ending in \".txt\" from your phone to your Google Drive, into the folder you just created."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Arv2fGV_Q7X"
      },
      "source": [
        "If you want to place the files somewhere else, you can modify the file paths below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L1u07GM4-DNk"
      },
      "outputs": [],
      "source": [
        "# setting default file paths\n",
        "myPath = '/content/drive/MyDrive/Facial Data'\n",
        "outputPath = myPath + '/output'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NBYCC60-b-J"
      },
      "source": [
        "#Start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M96PIATF_n3t"
      },
      "source": [
        "Now, press the \"Runtime\" button in the top left and click \"Run All\"\n",
        "If Google gives you warnings, click \"Run anyways.\"\n",
        "Additionally, you will need to connect your Google Drive to Google Colab, so make sure to sign in to Google when prompted to mount your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-43SHZfvZADH"
      },
      "source": [
        "After a few minutes, you should see some output files in the \"output\" folder in the \"Facial Data\" folder. The amount of time required for processing increases if you have more than one data file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wykT-EXpMt69"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B0OoZubwSh7"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_CCMDl6YR1qG"
      },
      "outputs": [],
      "source": [
        "# importing needed modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from operator import itemgetter\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dNQYXclQgCO"
      },
      "outputs": [],
      "source": [
        "# if mpld3 is not already installed, install it\n",
        "installedPackages = !pip list -v\n",
        "installed = False\n",
        "for package in installedPackages:\n",
        "  if package[0:5] == 'mpld3':\n",
        "    installed = True\n",
        "if installed == False:\n",
        "  !pip install mpld3\n",
        "\n",
        "# import mpld3\n",
        "import mpld3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIeDknEwFL5m"
      },
      "source": [
        "##Setup Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BZoI285nFLdO"
      },
      "outputs": [],
      "source": [
        "def importData(myfile, myPath):\n",
        "  \"\"\"\n",
        "  imports the data from the file to a dataframe\n",
        "  myFile: string\n",
        "    the name of the text file where the data is located, including the filetype suffix\n",
        "  myPath: string\n",
        "    the path where the file is stored\n",
        "\n",
        "  returns:\n",
        "    imported dataframe\n",
        "  \"\"\"\n",
        "  pathFull = myPath + \"/\" + myfile\n",
        "  data = pd.read_csv(pathFull, header = None, skiprows=22)\n",
        "  data.columns = my_cols\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZSaNw1NGFUWv"
      },
      "outputs": [],
      "source": [
        "def derivative(x,y):\n",
        "  \"\"\"\n",
        "  inputs x and y lists and returns the x and y lists for that graph's derivative:\n",
        "  reduces the length of x by 1 and takes the derivative of y\n",
        "  x: list, array\n",
        "  y: list, array\n",
        "    the x and y lists for a graph\n",
        "\n",
        "  returns:\n",
        "    the modified x and y lists\n",
        "  \"\"\"\n",
        "  dydx = np.diff(y)/np.diff(x)\n",
        "  dydx_x = x[:-1]\n",
        "  return dydx_x, dydx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qp4i0xh7FXmB"
      },
      "outputs": [],
      "source": [
        "def generateDerivativeFrames(df):\n",
        "  \"\"\"\n",
        "  creates dataframes for the derivatives of a dataframe's columns\n",
        "  data: dataframe\n",
        "    the name of the text file where the data is located, including the filetype suffix\n",
        "\n",
        "  returns:\n",
        "    der1: the first derivative of the columns of data\n",
        "    der2: the second derivative of the columns of data\n",
        "  \"\"\"\n",
        "  der1 = pd.DataFrame()\n",
        "  der2 = pd.DataFrame()\n",
        "\n",
        "  # create derivative 1\n",
        "  der1 = pd.concat([der1, df[\"bs\"][:-1]], axis=1)\n",
        "  der1 = pd.concat([der1, df[Milliseconds][:-1]], axis=1)\n",
        "  for col in df.columns[2:]:\n",
        "    column = df[col]\n",
        "    x = []\n",
        "    x, column_der = derivative(df[Milliseconds], column)\n",
        "    column_der = pd.Series(column_der)\n",
        "    der1 = pd.concat([der1, column_der.rename(col)], axis=1)\n",
        "\n",
        "  # create derivative 2\n",
        "  der2 = pd.concat([der2, df[\"bs\"][:-2]], axis=1)\n",
        "  der2 = pd.concat([der2, df[Milliseconds][:-2]], axis=1)\n",
        "  for col in der1.columns[2:]:\n",
        "    column = der1[col]\n",
        "    x = []\n",
        "    x, column_der2 = derivative(der1[Milliseconds], column)\n",
        "    column_der2 = pd.Series(column_der2)\n",
        "    der2 = pd.concat([der2, column_der2.rename(col)], axis=1)\n",
        "\n",
        "  return der1, der2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ebC2JVV-nvPA"
      },
      "outputs": [],
      "source": [
        "def findInDf(number, df):\n",
        "  while True:\n",
        "    try:\n",
        "      start = list(df[Milliseconds]).index(number)\n",
        "      break\n",
        "    except:\n",
        "      number+=1\n",
        "\n",
        "  return start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EZF-RNXWPfWq"
      },
      "outputs": [],
      "source": [
        "def saveGraph(fig, name):\n",
        "  fileName = f'{outputPath}/{name}.png'\n",
        "  fig.savefig(fileName)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCZ1A-F3FNno"
      },
      "source": [
        "##Mount Drive & Make Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ogtZe2H7FQMe"
      },
      "outputs": [],
      "source": [
        "# mount drive\n",
        "if not os.path.isdir(os.path.join('/content/drive', 'My Drive')):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "# make output dir\n",
        "if not os.path.exists(outputPath):\n",
        "  os.mkdir(outputPath)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zht61QeWLure"
      },
      "source": [
        "##Establish Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "I2v5ZIbuHbd7"
      },
      "outputs": [],
      "source": [
        "# creating a default dataframe\n",
        "data = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "89QZGFHEKh2d"
      },
      "outputs": [],
      "source": [
        "# setting column titles to correspond to the blendshapes they represent\n",
        "my_cols = ['bs', 'Milliseconds', 'head x', 'head y', 'head z', 'EA x', 'EA y',\n",
        "       'EA z', 'LE x', 'LE y', 'RE x', 'RE y', 'browInnerUp', 'browDown_L',\n",
        "       'browDown_R', 'browOuterUp_L', 'browOuterUp_R', 'eyeLookUp_L',\n",
        "       'eyeLookUp_R', 'eyeLookDown_L', 'eyeLookDown_R', 'eyeLookIn_L',\n",
        "       'eyeLookIn_R', 'eyeLookOut_L', 'eyeLookOut_R', 'eyeBlink_L',\n",
        "       'eyeBlink_R', 'eyeSquint_L', 'eyeSquint_R', 'eyeWide_L', 'eyeWide_R',\n",
        "       'cheekPuff', 'cheekSquint_L', 'cheekSquint_R', 'noseSneer_L',\n",
        "       'noseSneer_R', 'jawOpen', 'jawForward', 'jawLeft', 'jawRight',\n",
        "       'mouthFunnel', 'mouthPucker', 'mouthLeft', 'mouthRight',\n",
        "       'mouthRollUpper', 'mouthRollLower', 'mouthShrugUpper',\n",
        "       'mouthShrugLower', 'mouthClose', 'mouthSmile_L', 'mouthSmile_R',\n",
        "       'mouthFrown_L', 'mouthFrown_R', 'mouthDimple_L', 'mouthDimple_R',\n",
        "       'mouthUpperUp_L', 'mouthUpperUp_R', 'mouthLowerDown_L',\n",
        "       'mouthLowerDown_R', 'mouthPress_L', 'mouthPress_R', 'mouthStretch_L',\n",
        "       'mouthStretch_R', 'tongueOut']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Cwab_Umuxtaa"
      },
      "outputs": [],
      "source": [
        "# defining pairs of columns\n",
        "colPairs = {\n",
        "  'EulerAngles': ['EA x', 'EA y'],\n",
        "  'EyeX':['LE x', 'RE x'],\n",
        "  'EyeY': ['LE y', 'RE y'],\n",
        "  'browDown':['browDown_L', 'browDown_R'],\n",
        "  'browOuterUp':['browOuterUp_L', 'browOuterUp_R'],\n",
        "  'eyeLookUp':['eyeLookUp_L', 'eyeLookUp_R'],\n",
        "  'eyeLookDown':['eyeLookDown_L', 'eyeLookDown_R'],\n",
        "  'eyeLookIn':['eyeLookIn_L', 'eyeLookIn_R'],\n",
        "  'eyeLookOut':['eyeLookOut_L', 'eyeLookOut_R'],\n",
        "  'eyeBlink':['eyeBlink_L', 'eyeBlink_R'], \n",
        "  'eyeSquint':['eyeSquint_L', 'eyeSquint_R'], \n",
        "  'eyeWide':['eyeWide_L', 'eyeWide_R'],\n",
        "  'cheekSquint':['cheekSquint_L', 'cheekSquint_R'], \n",
        "  'noseSneer':['noseSneer_L', 'noseSneer_R'], \n",
        "  'jaw':['jawLeft', 'jawRight'],\n",
        "  'mouth':['mouthLeft', 'mouthRight'],\n",
        "  'mouthRoll':['mouthRollUpper', 'mouthRollLower'] ,\n",
        "  'mouthShrug':['mouthShrugUpper',  'mouthShrugLower'], \n",
        "  'mouthSmile':['mouthSmile_L', 'mouthSmile_R'],\n",
        "  'mouthFrown':['mouthFrown_L', 'mouthFrown_R'], \n",
        "  'mouthDimple':['mouthDimple_L', 'mouthDimple_R'],\n",
        "  'mouthUpper':['mouthUpperUp_L', 'mouthUpperUp_R'],\n",
        "  'mouthLower':['mouthLowerDown_L','mouthLowerDown_R'], \n",
        "  'mouthPress':['mouthPress_L', 'mouthPress_R'], \n",
        "  'mouthStretch':['mouthStretch_L','mouthStretch_R']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YFLXq-o_KulZ"
      },
      "outputs": [],
      "source": [
        "# defines Milliseconds as the string of the millisecond column\n",
        "Milliseconds = my_cols[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-10IClfXNE8q"
      },
      "source": [
        "##Read in Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yW5fAlh9ADJT"
      },
      "outputs": [],
      "source": [
        "#importing the data tables to dataframes\n",
        "dfs = []\n",
        "dfsNames = []\n",
        "dfs_vel = []\n",
        "dfs_accel = []\n",
        "i=0\n",
        "\n",
        "for filename in os.listdir(myPath):\n",
        "    if filename.endswith(\"txt\"): \n",
        "        dfs.append(importData(filename, myPath))\n",
        "        dfsNames.append(filename[:-4])\n",
        "        tempData1, tempData2 = generateDerivativeFrames(dfs[i])\n",
        "        dfs_vel.append(tempData1)\n",
        "        dfs_accel.append(tempData2)\n",
        "        i+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJuFMNe7-ndR"
      },
      "source": [
        "#Graphing & Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqrZPRSM1PyH"
      },
      "source": [
        "##Graph Column or ColPair Section (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hs-UYpVt1TeE"
      },
      "outputs": [],
      "source": [
        "def GraphColumnsSection(colTitles = [], df = data, xstart = 0, xend = None, together = False):\n",
        "  \"\"\"\n",
        "  graphs the given columns from the given dataframe, with a restricted x axis\n",
        "  colTitles: list, array\n",
        "    a list or array of all names of columns which will be graphed\n",
        "  df: dataframe\n",
        "    the dataframe that the columns will be from\n",
        "  together: boolean\n",
        "    Whether or not the graphs will be overlayed or not\n",
        "  xstart: integer\n",
        "    The lowest value for the x axis\n",
        "  xend: integer\n",
        "    The highest value for the x axis\n",
        "  \"\"\"\n",
        "  # if xend is not input\n",
        "  if xend == None:\n",
        "    # set the maximum x value to the highest it can be with the given dataframe\n",
        "    xend = max(df[Milliseconds])\n",
        "  # if together is True, graph both graphs on the same axis\n",
        "  if together:\n",
        "    fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
        "    for colTitle in colTitles:\n",
        "      ax.plot(df[Milliseconds], df[colTitle], label = colTitle)\n",
        "      ax.legend()\n",
        "      ax.set_xlim(xstart, xend)\n",
        "  # otherwise, graph them on different axes\n",
        "  else:\n",
        "    fig, ax = plt.subplots(len(colTitles), 1, figsize = (8, 6*len(colTitles)))\n",
        "    for i in range(len(colTitles)):\n",
        "      ax[i].plot(df[Milliseconds], df[colTitles[i]], label = colTitles[i])\n",
        "      ax[i].legend()\n",
        "      ax[i].set_xlim(xstart, xend)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "hH4MEkUeja8V"
      },
      "outputs": [],
      "source": [
        "def GraphColPairsSection(pairs = [], df = data, xstart = 0, xend = None, normalized = False):\n",
        "  \"\"\"\n",
        "  graphs the given column pairs from the given dataframe, with a restricted x axis\n",
        "  pairs: list, array\n",
        "    a list or array of all names of column pairs which will be graphed\n",
        "  df: dataframe\n",
        "    the dataframe that the columns will be from\n",
        "  xstart: integer\n",
        "    The lowest value for the x axis\n",
        "  xend: integer\n",
        "    The highest value for the x axis\n",
        "  \"\"\"\n",
        "  # if xend is not input\n",
        "  if xend == None:\n",
        "    # set the maximum x value to the highest it can be with the given dataframe\n",
        "    xend = max(df[Milliseconds])\n",
        "  # create figure and axis\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
        "  # graph each pair with the restricted x axis\n",
        "  for pairName in pairs:\n",
        "    colPairs[pairName][0]\n",
        "    ax.plot(df[Milliseconds], df[colPairs[pairName][0]], label = colPairs[pairName][0])\n",
        "    ax.plot(df[Milliseconds], df[colPairs[pairName][1]], label = colPairs[pairName][1])\n",
        "    ax.legend()\n",
        "    ax.set_xlim(xstart, xend)\n",
        "    if normalized == True:\n",
        "      ax.set_ylim(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def findPairDifference(pair, df, xstart = 0, xend = None):\n",
        "  # pair: name of a colPair\n",
        "  # df: a dataframe\n",
        "  # xstart: starting time interval value\n",
        "  # xend: ending time interval value\n",
        "  # returns the percentage difference between two symmetrical blendshapes\n",
        "  # as well as a graph with the cumulative percentage difference\n",
        "  # between the Left and Right blendshapes (indexes 0 and 1 in the colPair)\n",
        "\n",
        "  # if the resulting percentage is positive, the left blendshape (index 0 in the colPair) has higher values than the right\n",
        "  # if the resulting percentage is negative, the right blendshape (index 1 in the colPair) has higher values than the left\n",
        "\n",
        "  if xend == None:\n",
        "    xend = max(df[Milliseconds])\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
        "  ax.plot(df[Milliseconds], df[colPairs[pair][0]], label = colPairs[pair][0])\n",
        "  ax.plot(df[Milliseconds], df[colPairs[pair][1]], label = colPairs[pair][1])\n",
        "\n",
        "  pointDifferences = []\n",
        "  timeRange = df[Milliseconds][findInDf(xstart, df):findInDf(xend, df)]\n",
        "  for i in range(len(timeRange)):\n",
        "    left = df[colPairs[pair][0]][i]\n",
        "    right = df[colPairs[pair][1]][i]\n",
        "    pointDiff = (left-right)/max([left, right])\n",
        "    pointDifferences.append(pointDiff)\n",
        "  totaldiff = np.sum(pointDifferences)/len(timeRange)\n",
        "\n",
        "  print(totaldiff*100)\n",
        "  cumulative = np.cumsum(pointDifferences)/len(timeRange)\n",
        "  ax.plot(timeRange, cumulative, label = \"Cumulative % Difference\")\n",
        "\n",
        "  ax.legend()\n",
        "  ax.set_xlim(xstart, xend)"
      ],
      "metadata": {
        "id": "XGV-NebH9yvU"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tk2Eadx3wKL"
      },
      "source": [
        "##Graph All (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AqKm7WrhfSjP"
      },
      "outputs": [],
      "source": [
        "def graphAll(dfs = [], titles = [], skinnyGraph = True, scaled = False):\n",
        "  \"\"\"\n",
        "  graphs all of the columns for each of the given dataframes\n",
        "  the format of the graph depends on the 'skinnyGraph' variable\n",
        "  dfs: list\n",
        "    the list of dataframes which will have thier columns graphed\n",
        "  titles: list\n",
        "    the list of titles corresponding to the dataframes\n",
        "    the first element of titles will be used to label the first element of dfs, etc.\n",
        "  skinnyGraph: boolean\n",
        "    if True, each dataframe will occupy only one column\n",
        "    if False, the graphs will still be next to each other, but will occupy multiple columns\n",
        "  scaled: boolean\n",
        "    if True, the y axis will go from 0 to 1\n",
        "\n",
        "  returns:\n",
        "    the graph of all the columns of each dataframe\n",
        "  \"\"\"\n",
        "  # calculates graph size based on the amount of dataframes input\n",
        "  if skinnyGraph == True:\n",
        "    totalRows = len(dfs[0].columns)-2\n",
        "    totalColumns = len(dfs)\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "  else:\n",
        "    totalGraphsNum = len(dfs)*(len(dfs[0].columns)-2)\n",
        "    totalRows = math.floor(math.sqrt(totalGraphsNum))\n",
        "    totalColumns = math.ceil(totalGraphsNum/totalRows)\n",
        "    while totalColumns % len(dfs) != 0:\n",
        "      totalColumns+=1\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "\n",
        "  # create the figure and axis\n",
        "  fig, ax = plt.subplots(totalRows, totalColumns, figsize = figsize)\n",
        "  # if scaled is true, limit the y axis\n",
        "  if scaled == True:\n",
        "    plt.setp(ax, ylim = (0, 1))\n",
        "  # create the graph and save it to a file\n",
        "  row = 0\n",
        "  column = 0\n",
        "  colTitles = dfs[0].columns[2:]\n",
        "  # if there is more than one column, create the graph via this logic\n",
        "  if totalColumns > 1:\n",
        "    for col in colTitles:\n",
        "      for i in range(0, len(dfs)):\n",
        "        x=dfs[i][Milliseconds]\n",
        "        y=dfs[i][col]\n",
        "\n",
        "        ax[row, column+i].plot(x,y, label=col)\n",
        "        ax[row, column+i].set_title(f'{titles[i]}')\n",
        "        ax[row, column+i].legend()\n",
        "      row+=1\n",
        "      if row%totalRows==0:\n",
        "        row = 0\n",
        "        column+=len(dfs)\n",
        "  # otherwise, use this logic\n",
        "  else:\n",
        "    for col in colTitles:\n",
        "      x=dfs[0][Milliseconds]\n",
        "      y=dfs[0][col]\n",
        "\n",
        "      ax[row].plot(x,y, label=col)\n",
        "      ax[row].set_title(f'{titles[0]}')\n",
        "      ax[row].legend()\n",
        "      row+=1\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MqO3dcIT65_X"
      },
      "outputs": [],
      "source": [
        "def graphAllToFile(dfs = [], titles = [], skinnyGraph = True, scaled = False):\n",
        "  \"\"\"\n",
        "  graphs all of the columns for each of the given dataframes and outputs them to a file\n",
        "  the format of the graph depends on the 'skinnyGraph' variable\n",
        "  dfs: list\n",
        "    the list of dataframes which will have thier columns graphed\n",
        "  titles: list\n",
        "    the list of titles corresponding to the dataframes\n",
        "    the first element of titles will be used to label the first element of dfs, etc.\n",
        "  skinnyGraph: boolean\n",
        "    if True, each dataframe will occupy only one column\n",
        "    if False, the graphs will still be next to each other, but will occupy multiple columns\n",
        "  scaled: boolean\n",
        "    if True, the y axis will go from 0 to 1\n",
        "  \"\"\"\n",
        "  fig = graphAll(dfs,titles)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(titles)):\n",
        "    nametotal = nametotal + titles[index] + \"-\"\n",
        "  saveGraph(fig, f\"{nametotal}All Graphs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1txNAih4csBT"
      },
      "source": [
        "##Fourier Transform Functions (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YpyMQC6FkoTJ"
      },
      "outputs": [],
      "source": [
        "def compareFourierTransforms(dfs = [], titles = [], skinnyGraph = True):\n",
        "  \"\"\"\n",
        "  outputs graphs of the fourier transforms of each column in the input dataframes\n",
        "  dfs: list\n",
        "    the list of dataframes that will have their columns' fourier transforms compared\n",
        "  titles: list\n",
        "    the names of the corresponding output columns\n",
        "    the 1st name will be attached to the first dataframe, and so on\n",
        "  skinnyGraph: boolean\n",
        "    If true, the graph will have as many columns as dataframes input\n",
        "    If false, the graph will instead be more square-shaped\n",
        "  returns:\n",
        "    a graph with the fourier transforms for each column in the given dataframes\n",
        "  \"\"\"\n",
        "  # seting graph sizes\n",
        "  if skinnyGraph == True:\n",
        "    totalRows = len(my_cols[12:])\n",
        "    totalColumns = len(dfs)\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "  else:\n",
        "    totalGraphsNum = len(dfs)*len(my_cols[12:])\n",
        "    totalRows = math.floor(math.sqrt(totalGraphsNum))\n",
        "    totalColumns = math.ceil(totalGraphsNum/totalRows)\n",
        "    while totalColumns % len(dfs) != 0:\n",
        "       totalColumns+=1\n",
        "    figsize=(8*totalColumns, 6*totalRows)\n",
        "\n",
        "  fig, ax = plt.subplots(totalRows, totalColumns, figsize = figsize)\n",
        "\n",
        "  # creating the fourier transforms at their appropriate location in the graph\n",
        "  for i in range(len(dfs)):\n",
        "    for j in range(len(my_cols[12:])):\n",
        "      FFT = np.fft.fft(dfs[i][my_cols[j+12]])\n",
        "      freq = np.arange(len(dfs[i][Milliseconds]))/dfs[i][Milliseconds][len(dfs[i][Milliseconds])-1] # scale by dividing by max time\n",
        "      ax[j][i].plot(freq,np.abs(FFT))\n",
        "      ax[j][i].set_title(f\"{titles[i]}, {my_cols[j+12]}\")\n",
        "\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "F7hyWRE4cupQ"
      },
      "outputs": [],
      "source": [
        "def fourierTransform(df = data):\n",
        "  \"\"\"\n",
        "  displays all graphs for the fourier transforms in a given dataframe\n",
        "  data: dataframe\n",
        "    the dataframe that has columns that will be input into the fourier transform\n",
        "  returns:\n",
        "    multiple graphs, each of a column that has been input into the fourier transform\n",
        "  \"\"\"\n",
        "  for col in my_cols[2:]:\n",
        "    SecondsfromNano = df[Milliseconds]/1000\n",
        "    \n",
        "    FFT = np.fft.fft(df[col])\n",
        "    freq = np.arange(len(SecondsfromNano))/SecondsfromNano[len(SecondsfromNano)-1] # scale by dividing by max time\n",
        "    fig, ax = plt.subplots(1,1, figsize = (10,8))\n",
        "    ax.set_xlim(0, 30)\n",
        "    ax.plot(freq,np.abs(FFT))\n",
        "    ax.set_title(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bG5kXkwXpDZA"
      },
      "outputs": [],
      "source": [
        "def fourierTransformInterval(df = data, col = \"LE x\", startinit = 0, endinit = 10000, xlim = (0, 30), ylim = None):\n",
        "  \"\"\"\n",
        "  performs a fourier transform on a certain interval for a specific column in a specific dataframe\n",
        "  df: dataframe\n",
        "    the dataframe input\n",
        "  col: string\n",
        "    the name of the column to be input\n",
        "  startinit: integer\n",
        "    the lower bound for the fourier transform\n",
        "  endinit: integer\n",
        "    the higher bound for the fourier transform\n",
        "  xlim: tuple\n",
        "    the bounds for the x-axis\n",
        "  ylim: tuple\n",
        "    the bounds for the y-axis\n",
        "    If not input, the y axis will be automatically assigned\n",
        "  \"\"\"\n",
        "  start = findInDf(startinit, df)\n",
        "  end = findInDf(endinit, df)\n",
        "\n",
        "  SecondsfromNano = df[Milliseconds][start:end]/1000\n",
        "\n",
        "  FFT = np.fft.fft(df[col][start:end])\n",
        "  freq = np.arange(len(SecondsfromNano))/(SecondsfromNano[end-1]-SecondsfromNano[start]) # scale by dividing by max time\n",
        "  fig, ax = plt.subplots(1,1, figsize = (10,8))\n",
        "  ax.set_xlim(xlim)\n",
        "  if ylim != None:\n",
        "    ax.set_ylim(ylim)\n",
        "  ax.plot(freq,np.abs(FFT))\n",
        "  ax.set_title(col)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nOQYFshEDRBN"
      },
      "outputs": [],
      "source": [
        "def fourierTransformAutoInterval(df = data, col = \"LE x\", interval = 1000, xlim = (0, 30), ylim = None):\n",
        "  ms = 0\n",
        "  while ms+interval < max(df[Milliseconds]):\n",
        "    print(f\"Interval: {ms} to {ms+interval}\")\n",
        "    fourierTransformInterval(df, col, ms, ms+interval, xlim, ylim)\n",
        "    ms+=interval\n",
        "  fourierTransformInterval(df, col, ms, max(df[Milliseconds]), xlim, ylim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f40eoc2GPZyp"
      },
      "source": [
        "#Peaks and Valleys"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyyGQUbAcIsq"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UfYjb_NX5lxk"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysDF(dataTitle, df, ax = None, displaygraph = False):\n",
        "  \"\"\"\n",
        "  creates a list of all points in data where each point is equal to the points adjacent to it\n",
        "  dataTitle: string\n",
        "    the name of a column in data\n",
        "  ax:\n",
        "    the axis of a given graph\n",
        "    multiple axis elements are stored as an np.ndarray\n",
        "\n",
        "  returns:\n",
        "    a list of points, where each point is equal to the points adjacent to it\n",
        "  \"\"\"\n",
        "  pav = []\n",
        "  # if ax is a list, set it to its first graph\n",
        "  if type(ax) is np.ndarray:\n",
        "    ax = ax[0]\n",
        "  # for each point in the given column\n",
        "  for n in range(1, len(df[dataTitle])-1):\n",
        "    # if this point is increaseing, color it red\n",
        "    if df[dataTitle][n-1] < df[dataTitle][n] and df[dataTitle][n] < df[dataTitle][n+1]:\n",
        "      if displaygraph == True:\n",
        "        ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Red')\n",
        "      else:\n",
        "        pass\n",
        "    # if this point is decreasing, color it green\n",
        "    elif df[dataTitle][n-1] > df[dataTitle][n] and df[dataTitle][n] > df[dataTitle][n+1]:\n",
        "      if displaygraph == True:\n",
        "        ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Green')\n",
        "      else:\n",
        "        pass\n",
        "    # if this graph is neither increasing nor decreasing, append it to pav\n",
        "    else:\n",
        "      pav.append((df[Milliseconds][n], df[dataTitle][n]))\n",
        "  # color all points in pav black\n",
        "  if displaygraph == True:\n",
        "    # add the graph line to the graph\n",
        "    ax.plot(df[Milliseconds], df[dataTitle], zorder = 0, label = dataTitle)\n",
        "    for n in pav:\n",
        "      ax.scatter(n[0], n[1], color = 'Black')\n",
        "    ax.legend()\n",
        "    return ax\n",
        "  if displaygraph == False:\n",
        "    return pav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "T7WmzSzXHJD-"
      },
      "outputs": [],
      "source": [
        "def createPavFrame(dataTitle, pav, df, minimumLength = 4, skipDivisor = 8):\n",
        "  \"\"\"\n",
        "  creates a DataFrame that has all of the peaks and valleys in pav, one peak or valley for each column\n",
        "  dataTitle: string\n",
        "    the name of a column in the dataframe\n",
        "  pav:\n",
        "    the output of the pav function for the given dataTitle\n",
        "  df:\n",
        "    the dataframe for data to be drawn from\n",
        "  minimumLength:\n",
        "    the minimum amount of points for a group of points to be considered a peak or valley\n",
        "  skipDivisor:\n",
        "    the divisor that helps determine the minimum distance between a peak and valley\n",
        "    the higher this is, the lower the minimum distance\n",
        "\n",
        "  returns:\n",
        "    a DataFrame that has all of the peaks and valleys in pav, one peak or valley for each column\n",
        "  \"\"\"\n",
        "  pavFrame = pd.DataFrame()\n",
        "\n",
        "  skipValue = (max(df[dataTitle])-min(df[dataTitle]))/skipDivisor\n",
        "  i = 0\n",
        "  tpoint = 0\n",
        "  for n in range(len(pav)-1):\n",
        "    index = findInDf(pav[n][0], df)\n",
        "    index2 = findInDf(pav[n+1][0], df)\n",
        "    if abs(df[dataTitle][index] - df[dataTitle][index2]) > skipValue or n==len(pav)-3:\n",
        "      j = n+1\n",
        "      ser = pd.Series(pav[i:j], name=f\"Peak/Valley {str(tpoint+1).zfill(zFillValue)}\")\n",
        "      if len(ser) > minimumLength:\n",
        "        tpoint=tpoint+1\n",
        "        pavFrame = pd.concat([pavFrame, ser], axis=1)\n",
        "      i = j\n",
        "  \n",
        "  return pavFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "MxWtU2RN9hCn"
      },
      "outputs": [],
      "source": [
        "def pavMidpoint(column):\n",
        "  \"\"\"\n",
        "  finds the x-value of the midpoint of a given column\n",
        "  column: list\n",
        "    a list of numbers\n",
        "\n",
        "  returns:\n",
        "    the x-value of the midpoint of a given column\n",
        "  \"\"\"\n",
        "  new = tupleFixer(column)\n",
        "\n",
        "  midPoint = np.nanmedian(new)\n",
        "  #if even number of elements, takes the lower of the two middle values\n",
        "  midPoint = new[new<=midPoint].max()\n",
        "\n",
        "  return midPoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "caxdbWitXIRv"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysSymmetryValues(dataTitle='jawForward', df = data):\n",
        "  \"\"\"\n",
        "  creates and displays a dictionary for the peaks and valleys of the given\n",
        "  dataframe, where the key is the peak number in the format 'Peak/Valley XXX',\n",
        "  and the value is a list with the x-value of where the peak or valley appears\n",
        "  and the symmetry value for that peak or valley\n",
        "  dataTitle:\n",
        "    the column of the dataframe\n",
        "  df:\n",
        "    the dataframe which data will be taken from\n",
        "\n",
        "  returns:\n",
        "    none, displays dictionary of peaks and valleys and a graph that shows\n",
        "    which points are increasing, which remain the same, and which ones are \n",
        "    decreasing\n",
        "  \"\"\"\n",
        "  #creating pav AND adding the graphical dots\n",
        "  pav = peaksAndValleysDF(dataTitle, df)\n",
        "\n",
        "  #creating & populating pavFrame\n",
        "  pavFrame = createPavFrame(dataTitle, pav, df)\n",
        "\n",
        "  #creating pavdict\n",
        "  pavDict = {}\n",
        "  # for each peak or valley\n",
        "  for n in range(1, len(pavFrame.columns)+1):\n",
        "    # create a string that is 5 characters long, consisting of left zeros in empty places\n",
        "    # this string will be the title of the corresponding peak or valley midpoint\n",
        "    sortedN = str(n).zfill(zFillValue)\n",
        "    #establish title\n",
        "    titleOfPoint=f\"Peak/Valley {sortedN}\"\n",
        "    # find the midpoint of the entries in the given column of pavFrame, converted to int\n",
        "    midpointOfPavFrameColumn = int(pavMidpoint(pavFrame[titleOfPoint]))\n",
        "    # finding the symmetry value that corresponds to dataTitle in data\n",
        "    # then, round the symmetry value to 4 decimal places\n",
        "    dataTitleSymmetryValue = symmetryValue(pavFrame[titleOfPoint], dataTitle, df)\n",
        "    dataTitleSymmetryValueRounded = np.round(dataTitleSymmetryValue, 4)\n",
        "    # create an entry in pavDict with a title \"titleofPoint\" that corresponds to (x, symmetry)\n",
        "    # where x is the time value for the midpoint of given peak/valley\n",
        "    # where symmetry is the symmetry value for the given peak/valley\n",
        "    pavDict[titleOfPoint] = [midpointOfPavFrameColumn, dataTitleSymmetryValueRounded]\n",
        "  \n",
        "  return pavDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZiuZQHkcG8b"
      },
      "source": [
        "##Peaks and Valleys Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9T7zN0fgSB1K"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysLengths(pavNumber, dataTitle, df, minimumLength = 4, skipDivisor = 8):\n",
        "  pav = peaksAndValleysDF(dataTitle, df)\n",
        "  pavFrame = createPavFrame(dataTitle, pav, df, minimumLength, skipDivisor)\n",
        "\n",
        "  titleNum = str(pavNumber).zfill(zFillValue)\n",
        "  title=f\"Peak/Valley {titleNum}\"\n",
        "\n",
        "  pavCol = pavFrame[title].dropna()\n",
        "  length = len(pavCol)-1\n",
        "  beginningpoint = pavCol[0][0]\n",
        "  endingpoint = pavCol[length][0]\n",
        "\n",
        "  print(f\"Length of Peak/Valley: {abs(beginningpoint-endingpoint)}\")\n",
        "  print(f\"Starting point of Peak/Valley: {beginningpoint}\")\n",
        "  print(f\"Ending point of Peak/Valley: {endingpoint}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxYaJuBUbb1F"
      },
      "source": [
        "##Graphing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4FNS3FuMht-z"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysGraph(dataTitle, df, fig = None, ax = None):\n",
        "  \"\"\"\n",
        "  visualizes on a graph which points in the given column of df are the decreasing, increasing, or neither\n",
        "  dataTitle: string\n",
        "    the column to graph\n",
        "  df: dataframe\n",
        "    the dataframe from which to graph the column\n",
        "  ax: axis\n",
        "    the axis to graph on\n",
        "  \"\"\"\n",
        "  if fig == None or ax == None:\n",
        "    fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
        "  ax.plot(df[Milliseconds],df[dataTitle],zorder = -1)\n",
        "  # for each point in the given column\n",
        "  for n in range(1, len(df[dataTitle])-1):\n",
        "    # if this point is increasing, color it red\n",
        "    if df[dataTitle][n-1] < df[dataTitle][n] and df[dataTitle][n] < df[dataTitle][n+1]:\n",
        "      ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Red')\n",
        "      pass\n",
        "    # if this point is decreasing, color it green\n",
        "    elif df[dataTitle][n-1] > df[dataTitle][n] and df[dataTitle][n] > df[dataTitle][n+1]:\n",
        "      ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Green')\n",
        "      pass\n",
        "    # if this graph is neither increasing nor decreasing, color it black\n",
        "    else:\n",
        "      ax.scatter(df[Milliseconds][n], df[dataTitle][n], color = 'Black')\n",
        "\n",
        "  return fig, ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "60mpJO_GIhyt"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysGraphSmooth(dataTitle, df, minimumLength = 4, skipDivisor = 8):\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8*3, 6*3))\n",
        "  ax.plot(df[Milliseconds],df[dataTitle],zorder = -1, color = 'black')\n",
        "\n",
        "  #creating pav AND adding the graphical dots\n",
        "  pav = peaksAndValleysDF(dataTitle, df)\n",
        "  #creating & populating pavFrame\n",
        "  pavFrame = createPavFrame(dataTitle, pav, df, minimumLength, skipDivisor)\n",
        "\n",
        "  colorDict = ['r', 'orange', 'g', 'blue', 'purple', 'pink']\n",
        "  index = 0\n",
        "\n",
        "  groupNum = 1\n",
        "\n",
        "  for col in pavFrame:\n",
        "    pointGroup = []\n",
        "    # graph the point group and color it\n",
        "    for point in pavFrame[col]:\n",
        "      notNan = True\n",
        "      if point is np.NaN:\n",
        "        notNan = False\n",
        "      if notNan == True:\n",
        "        ax.scatter(point[0], point[1], color=colorDict[index])\n",
        "        pointGroup.append(point)\n",
        "    # label the group at the midpoint\n",
        "    midpoint = pointGroup[len(pointGroup)//2]\n",
        "    ymin, ymax = ax.get_ylim()\n",
        "    xincrease = -800\n",
        "    yincrease = abs(ymax-ymin)*0.065\n",
        "    plt.text(midpoint[0]+xincrease, midpoint[1]+yincrease, f\"{groupNum}\", fontSize = 24)\n",
        "    groupNum += 1\n",
        "    index+=1\n",
        "    if index > len(colorDict)-1:\n",
        "      index = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "apuLyynoB9x9"
      },
      "outputs": [],
      "source": [
        "def peaksAndValleysSpikes(dataTitle, df, intervalNum = 10, detailedIntervals = False, minimumLength = 4, skipDivisor = 8):\n",
        "  pav = peaksAndValleysDF(dataTitle, df)\n",
        "  pavFrame = createPavFrame(dataTitle, pav, df, minimumLength, skipDivisor)\n",
        "  pavMidpoints = []\n",
        "  for col in pavFrame:\n",
        "    midpoint = pavMidpoint(pavFrame[col])\n",
        "    pavMidpoints.append(midpoint)\n",
        "\n",
        "  CategoryValues = []\n",
        "  for i in range(intervalNum):\n",
        "    CategoryValues.append(0)\n",
        "\n",
        "  maximumX = max(df[Milliseconds])\n",
        "  deltaX = maximumX//intervalNum\n",
        "  prevX = 0\n",
        "  nextX = 0+deltaX\n",
        "\n",
        "  for i in range(intervalNum):\n",
        "    for x in pavMidpoints:\n",
        "      if x > prevX and x <= nextX:\n",
        "        CategoryValues[i]+=1\n",
        "    prevX+=deltaX\n",
        "    nextX+=deltaX\n",
        "\n",
        "  # category names\n",
        "  categories = []\n",
        "  prevX = 0\n",
        "  nextX = 0+deltaX\n",
        "  if detailedIntervals == True:\n",
        "    for i in range(intervalNum):\n",
        "      categories.append(f\"{prevX} - {nextX}\")\n",
        "      prevX+=deltaX\n",
        "      nextX+=deltaX\n",
        "  if detailedIntervals == False:\n",
        "    for i in range(intervalNum):\n",
        "      categories.append(f\"{i}\")\n",
        "  # graphing values\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (8*1.5, 6))\n",
        "  ax.bar(categories, CategoryValues)\n",
        "  if detailedIntervals == True:\n",
        "    plt.xticks(rotation = 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxpLX_ef_P0V"
      },
      "source": [
        "#Averages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-mIukfvJvIG"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DlVvdWJwaFB3"
      },
      "outputs": [],
      "source": [
        "def covertValuesToArray(dictionary = colPairs):\n",
        "  propertyColumn = list(dictionary.values())\n",
        "  expandedColumn = []\n",
        "  for i in propertyColumn:\n",
        "    for j in range(2):\n",
        "      expandedColumn.append(i[j])\n",
        "  return expandedColumn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB_ZakvtOXjC"
      },
      "source": [
        "##Average over an Interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yZC88lKowlxw"
      },
      "outputs": [],
      "source": [
        "def averageValuesFrame(dfs = [], names = [],individualColPairs = False):\n",
        "  if individualColPairs == False:\n",
        "    expandedColumn = covertValuesToArray(colPairs)\n",
        "    avgValueFrame = pd.DataFrame(expandedColumn, columns = [\"Blendshapes\"])\n",
        "\n",
        "    for i in range(len(dfs)):\n",
        "      avgValueList = []\n",
        "      for j in expandedColumn:\n",
        "        avgColValue = np.average(dfs[i][j])\n",
        "        avgValueList.append(avgColValue)\n",
        "      avgValueList = pd.Series(avgValueList)\n",
        "      avgValueFrame = pd.concat([avgValueFrame, avgValueList.rename(f\"{names[i]}\")], axis=1)\n",
        "    return avgValueFrame\n",
        "\n",
        "  if individualColPairs == True:\n",
        "    propertyColumn = list(colPairs.keys())\n",
        "    avgValueFrame = pd.DataFrame(propertyColumn, columns = [\"Blendshape Pairs\"])\n",
        "\n",
        "    for i in range(len(dfs)):\n",
        "      avgValueList = []\n",
        "      for j in propertyColumn:\n",
        "        colName1 = colPairs[j][0]\n",
        "        colName2 = colPairs[j][1]\n",
        "\n",
        "        avgColValue1 = np.average(dfs[i][colName1])\n",
        "        avgColValue2 = np.average(dfs[i][colName2])\n",
        "        avgColValue = np.average([avgColValue1, avgColValue2])\n",
        "\n",
        "        avgValueList.append(avgColValue)\n",
        "\n",
        "      avgValueList = pd.Series(avgValueList)\n",
        "      avgValueFrame = pd.concat([avgValueFrame, avgValueList.rename(f\"{names[i]}\")], axis=1)\n",
        "    return avgValueFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DmxdgJZDDloo"
      },
      "outputs": [],
      "source": [
        "def averageDataInterval(dataTitle=[Milliseconds], df = data, start=0, end=3000):\n",
        "  \"\"\"\n",
        "  prints the average of the values for each of the given columns over the given interval\n",
        "  dataTitle: list\n",
        "    a list of strings that are column names\n",
        "  start: int\n",
        "    the starting number in Milliseconds to begin averaging points at\n",
        "  end: int\n",
        "    the ending number in Milliseconds to begin averaging points at\n",
        "  \n",
        "  returns:\n",
        "    none\n",
        "    \n",
        "  example:\n",
        "    averageDataInterval([Milliseconds, 'browDown_L'], 0, 2000)\n",
        "  \"\"\"\n",
        "  # correct starting values in Milliseconds\n",
        "  start = findInDf(start, df)\n",
        "  end = findInDf(end, df)\n",
        "  # print interval range\n",
        "  print(f\"Averages over the interval [{df[Milliseconds][start]}, {df[Milliseconds][end]}]:\")\n",
        "  # for each column calculate and print averages\n",
        "  for cols in df:\n",
        "    #bs column error checking\n",
        "    if cols != my_cols[0]:\n",
        "      # calculate and print average value for a given column\n",
        "      averageOverInterval = np.average(df[cols][start:end])\n",
        "      print(f\"{cols}: {averageOverInterval}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKFmU4XdwlZz"
      },
      "source": [
        "##Average To File (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MZVsDFcycYcc"
      },
      "outputs": [],
      "source": [
        "def averageValuesToFile(dfs = [], names = [], individualColPairs = False):\n",
        "  \"\"\"\n",
        "  outputs the average values of the given dataframes to a file\n",
        "  \"\"\"\n",
        "  avgValuesFrame = averageValuesFrame(dfs, names, individualColPairs)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  avgValuesFrame.to_csv(f\"{outputPath}/{nametotal}Average Values.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSATt-PKXDzD"
      },
      "source": [
        "#Symmetry Analysis (UNUSED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRhAOkpMC7K0"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "dHsXUgPBSD99"
      },
      "outputs": [],
      "source": [
        "zFillValue = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Ws5B-2GXJys3"
      },
      "outputs": [],
      "source": [
        "def tupleFixer(column):\n",
        "  \"\"\"\n",
        "  creates an array with one-element entries\n",
        "  column: list\n",
        "    a list of numbers\n",
        "  ax:\n",
        "    the axis of a given graph\n",
        "    multiple axis elements are stored as an np.ndarray\n",
        "\n",
        "  returns:\n",
        "    an array that is the same as the input column, but replaces all tuples with only their x-value\n",
        "  \"\"\"\n",
        "  new = []\n",
        "  for x in column:\n",
        "    if x is np.nan:\n",
        "      new.append(x)\n",
        "    else:\n",
        "      new.append(x[0])\n",
        "  new = np.array(new)\n",
        "  return new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "eNNsh4ZUBUh6"
      },
      "outputs": [],
      "source": [
        "def symmetryValue(column, dataTitle, df = data, checkRange=10) :\n",
        "  \"\"\"\n",
        "  assigns a value to quantify the symmetry of a given dataTitle\n",
        "  column:\n",
        "    a column in a given pavFrame\n",
        "  dataTitle: string\n",
        "    the name of a column in the dataframe\n",
        "  checkRange:\n",
        "    the amount of points to the left and right that the function should search\n",
        "  df:\n",
        "    the dataframe for data to be drawn from\n",
        "\n",
        "  returns:\n",
        "    returns a value to quantify the symmetry of a given dataTitle\n",
        "  \"\"\"\n",
        "  midPointX = pavMidpoint(column)\n",
        "  midPointIndex = findInDf(midPointX, df)\n",
        "  midPointY = df[dataTitle][midPointIndex]\n",
        "\n",
        "  symmetryRange = df[dataTitle][midPointIndex-checkRange-1:midPointIndex+checkRange+2]\n",
        "\n",
        "  rightSideInc = None\n",
        "  leftSideInc = None\n",
        "  n = 1\n",
        "\n",
        "  while (rightSideInc == None or leftSideInc == None) and n<=checkRange+1:\n",
        "    if symmetryRange[midPointIndex] < symmetryRange[midPointIndex+n]:\n",
        "      rightSideInc = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex] > symmetryRange[midPointIndex+n]:\n",
        "      rightSideInc = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex] == symmetryRange[midPointIndex+n]:\n",
        "      rightSideInc = None\n",
        "    if symmetryRange[midPointIndex] < symmetryRange[midPointIndex-n]:\n",
        "      leftSideInc = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex] > symmetryRange[midPointIndex-n]:\n",
        "      leftSideInc = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex] == symmetryRange[midPointIndex-n]:\n",
        "      leftSideInc = None\n",
        "    n+=1\n",
        "\n",
        "  for n in range(2, checkRange):\n",
        "    if symmetryRange[midPointIndex+n-1] < symmetryRange[midPointIndex+n]:\n",
        "      currentChange = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex+n-1] > symmetryRange[midPointIndex+n]:\n",
        "      currentChange = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex+n-1] == symmetryRange[midPointIndex+n]:\n",
        "      currentChange = rightSideInc\n",
        "    if currentChange != rightSideInc:\n",
        "      checkRange = n-1\n",
        "      break\n",
        "    if symmetryRange[midPointIndex-n+1] < symmetryRange[midPointIndex-n]:\n",
        "      currentChange = \"Increasing\"\n",
        "    elif symmetryRange[midPointIndex-n+1] > symmetryRange[midPointIndex-n]:\n",
        "      currentChange = \"Decreasing\"\n",
        "    elif symmetryRange[midPointIndex-n+1] == symmetryRange[midPointIndex-n]:\n",
        "      currentChange = leftSideInc\n",
        "    if currentChange != leftSideInc and n-1 <= checkRange:\n",
        "      checkRange = n-1\n",
        "      break\n",
        "\n",
        "  symmetryRangeNew = df[dataTitle][midPointIndex-checkRange:midPointIndex+checkRange+1]\n",
        "\n",
        "  symmetryNumbers = []\n",
        "  for n in range(1,checkRange+1):\n",
        "    x = abs(symmetryRangeNew[midPointIndex]-symmetryRangeNew[midPointIndex-n])\n",
        "    symmetryNumbers.append(x)\n",
        "    x = abs(symmetryRangeNew[midPointIndex+n]-symmetryRangeNew[midPointIndex])\n",
        "    symmetryNumbers.append(x)\n",
        "  return np.mean(symmetryNumbers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bzrq7AUWGAVc"
      },
      "outputs": [],
      "source": [
        "def symmetryValuesPosition(dataTitle, df = data):\n",
        "  tempSymmetryValues = []\n",
        "  for i, j in zip(df[dataTitle[0]], df[dataTitle[1]]):\n",
        "    if i+j==0:\n",
        "      tempSymmetryValues.append(0)\n",
        "    else:\n",
        "      tempSymmetryValues.append(np.round(abs((j-i)/((i+j)/2)), 4))\n",
        "  return np.mean(tempSymmetryValues)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqFkhYhvULA9"
      },
      "source": [
        "#Symmetry Comparison (UNUSED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzQ2Od3ESJ7z"
      },
      "source": [
        "##Internal Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8KBqiXYcY3rF"
      },
      "outputs": [],
      "source": [
        "def getSymmetryValue(y1, y2):\n",
        "  tempSymmetryValues = []\n",
        "  for i, j in zip(y1, y2):\n",
        "    if i+j==0:\n",
        "      tempSymmetryValues.append(0)\n",
        "    else:\n",
        "      difference = abs((j-i))\n",
        "      tempSymmetryValues.append(difference)\n",
        "  averageSymmetryValue = np.mean(tempSymmetryValues)\n",
        "  return np.round(averageSymmetryValue, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "aeNLGNlGT5p-"
      },
      "outputs": [],
      "source": [
        "def skinnyGraphSizes(dfs = []): \n",
        "  totalRows = len(colPairs.keys())\n",
        "  totalColumns = len(dfs)\n",
        "  figsize=(8*totalColumns, 6*totalRows)\n",
        "  return totalRows, totalColumns, figsize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "wbgVl_gZS9U2"
      },
      "outputs": [],
      "source": [
        "def squareGraphSizes(dfs = []):\n",
        "  totalGraphsNum = len(dfs)*len(colPairs.keys())\n",
        "  totalRows = math.floor(math.sqrt(totalGraphsNum))\n",
        "  totalColumns = math.ceil(totalGraphsNum/totalRows)\n",
        "  while totalColumns % len(dfs) != 0:\n",
        "      totalColumns+=1\n",
        "  figsize=(8*totalColumns, 6*totalRows)\n",
        "  return totalRows, totalColumns, figsize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "8rmQS_gtKZoP"
      },
      "outputs": [],
      "source": [
        "def graphColPair(dfs = [], titles = [],keys = [], ax = \"Placeholder\", totalRows = 5):\n",
        "  row = 0\n",
        "  column = 0\n",
        "\n",
        "  for key in keys:\n",
        "    for i in range(len(dfs)):\n",
        "      colTitles = colPairs[key]\n",
        "      x1=dfs[i][Milliseconds]\n",
        "      y11=dfs[i][colTitles[0]]\n",
        "      y12=dfs[i][colTitles[1]]\n",
        "\n",
        "      ax[row, column+i].plot(x1,y11, label=colTitles[0])\n",
        "      ax[row, column+i].plot(x1,y12, label=colTitles[1])\n",
        "      ax[row, column+i].set_title(f'{titles[i]}')\n",
        "      ax[row, column+i].legend()\n",
        "    row+=1\n",
        "    if row%totalRows==0:\n",
        "      row = 0\n",
        "      column+=len(dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUfp5VXXJhAc"
      },
      "source": [
        "##Compare Symmetry Graph Functions\n",
        "Functions that display graphs of columns of the data sets for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "tLYKzWpqYAvb"
      },
      "outputs": [],
      "source": [
        "def compareSymmetryGraphs(dfs = [], titles = [], skinnyGraph = True, scaled = False):\n",
        "  if skinnyGraph == True:\n",
        "    totalRows, totalColumns, figsize = skinnyGraphSizes(dfs)\n",
        "  else:\n",
        "    totalRows, totalColumns, figsize = squareGraphSizes(dfs)\n",
        "\n",
        "  fig, ax = plt.subplots(totalRows, totalColumns, figsize = figsize)\n",
        "  \n",
        "  if scaled == True:\n",
        "    plt.setp(ax, ylim = (0, 1))\n",
        "\n",
        "  graphColPair(dfs, titles, colPairs.keys(), ax, totalRows)\n",
        "  display(fig)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHIilKasTJs5"
      },
      "source": [
        "## Symmetry Values Functions\n",
        "Functions that the symmetry values for comparison between two parts of a colPair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qBH-O1vuZkb8"
      },
      "outputs": [],
      "source": [
        "def symmetryValues(dfs = [], names = []):\n",
        "  propertyColumn = list(colPairs.keys())\n",
        "  symmValueFrame = pd.DataFrame(propertyColumn, columns = [\"Blendshapes\"])\n",
        "\n",
        "  for i in range(len(dfs)):\n",
        "    symmValueList = []\n",
        "    for key in colPairs.keys():\n",
        "      col1 = dfs[i][colPairs[key][0]]\n",
        "      col2 = dfs[i][colPairs[key][1]]\n",
        "      symmValue = getSymmetryValue(col1, col2)\n",
        "      symmValueList.append(symmValue)\n",
        "    symmValueList = pd.Series(symmValueList)\n",
        "    symmValueFrame = pd.concat([symmValueFrame, symmValueList.rename(f\"{names[i]}\")], axis=1)\n",
        "  return symmValueFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye8zj_KmIqEt"
      },
      "source": [
        "##ToFile Functions (FINAL)\n",
        "Functions that create an output file for graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "FW7t9Jy_EzPJ"
      },
      "outputs": [],
      "source": [
        "def compareSymmetryGraphsToFile(dfs = [], names = [], skinnyGraph = True, scaled = False):\n",
        "  fig = compareSymmetryGraphs(dfs, names, skinnyGraph, scaled)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  saveGraph(fig, f\"{nametotal}Symmetry Graph\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7EDPLFXvhLHv"
      },
      "outputs": [],
      "source": [
        "def symmetryValuesToFile(dfs = [], names = []):\n",
        "  symmValueFrame = symmetryValues(dfs, names)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  symmValueFrame.to_csv(f\"{outputPath}/{nametotal}Symmetry Values.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxdv47_6_i9J"
      },
      "source": [
        "#Eye Blink Counting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwubzESWHn5I"
      },
      "source": [
        "##Count Blinks & Blinks per Second (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "N5WV8YFX_nJp"
      },
      "outputs": [],
      "source": [
        "def CountBlinks(df = data, tolerance = 0.1, middlePointMax = 10, name = \"\"):\n",
        "  \"\"\"\n",
        "  counts the amount of blinks in the given dataframe\n",
        "  does this my counting the amount of times that there is a low point followed by a high point\n",
        "  a low point is any point that is lower than \"tolerance\" of the midpoint\n",
        "  a high point is any point that is higher than \"tolerance\" of the midpoint\n",
        "  ex. if the average y value is 0.4:\n",
        "      any point with a y value lower than 0.2 would be a low point\n",
        "      any point with a y value higher than 0.6 would be a high point\n",
        "  if there are more than \"midpoint\" points within \"tolerance\" of the middle\n",
        "  the dataset must be manually reviewed, as the blink number would be innacurate\n",
        "\n",
        "  returns:\n",
        "  The amount of blinks and blinks per second for the given dataframe\n",
        "  \"\"\"\n",
        "  middlePoints = 0\n",
        "  pav_L = peaksAndValleysDF(\"eyeBlink_L\", df)\n",
        "  pav_R = peaksAndValleysDF(\"eyeBlink_R\", df)\n",
        "  pav = [pav_L, pav_R]\n",
        "\n",
        "  if name != \"\":\n",
        "    name+=\": \"\n",
        "\n",
        "  for i in range(len(pav)):\n",
        "    highestPav = max(pav[i], key=itemgetter(1))[1]\n",
        "    lowestPav = min(pav[i], key=itemgetter(1))[1]\n",
        "\n",
        "    mediumvalue = (highestPav+lowestPav)/2\n",
        "    lowbound = mediumvalue-tolerance\n",
        "    highbound = mediumvalue+tolerance\n",
        "\n",
        "    for j in pav[i]:\n",
        "      if j[1] > lowbound and j[1] < highbound:\n",
        "        middlePoints+=1\n",
        "    if middlePoints>=middlePointMax:\n",
        "      if i == 0:\n",
        "        LorR = \"L\"\n",
        "      if i == 1:\n",
        "        LorR = \"R\"\n",
        "      print(f\"{name}Please review eyeBlink_{LorR} Manually\")\n",
        "    else:\n",
        "      blinks = 0\n",
        "      seconds = max(df[Milliseconds])/1000\n",
        "\n",
        "      point0 = 0\n",
        "      point1 = 1\n",
        "      for y in pav[i][:-1]:\n",
        "        y1 = pav[i][point0][1]\n",
        "        y2 = pav[i][point1][1]\n",
        "        if y1 < lowbound and y2 > highbound:\n",
        "          blinks+=1\n",
        "        point0+=1\n",
        "        point1+=1\n",
        "\n",
        "      bps = blinks/seconds\n",
        "      if i == 0:\n",
        "        LorR = \"L\"\n",
        "      if i == 1:\n",
        "        LorR = \"R\"\n",
        "      print(f\"{name}eyeBlink_{LorR} has {blinks} blinks, for a total of {bps} blinks per second.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "FH4ux24oB-CG"
      },
      "outputs": [],
      "source": [
        "def showBlinkGraphs(df = data):\n",
        "  \"\"\"\n",
        "  Graphs the eyeBlink blendshapes for the given dataframe.\n",
        "  If the point has a positive slope, it is red\n",
        "  If the point has a negative slope, it is green\n",
        "  Otherwise, it is black\n",
        "  df: dataframe\n",
        "    the dataframe of which to graph the blink blendshapes\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(2, 1, figsize = (8, 12))\n",
        "  peaksAndValleysGraph(\"eyeBlink_L\", df, fig, ax[0])\n",
        "  ax[0].set_title(\"eyeBlink_L\")\n",
        "  peaksAndValleysGraph(\"eyeBlink_R\", df, fig, ax[1])\n",
        "  ax[1].set_title(\"eyeBlink_R\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeDtNPFrnJmS"
      },
      "source": [
        "##Blink Graphs To File (FINAL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "dybk4MUrnDF4"
      },
      "outputs": [],
      "source": [
        "def BlinkGraphsToFile(dfs = [], names = []):\n",
        "  \"\"\"\n",
        "  Graphs the eyeBlink blendshapes for the given dataframes and returns them in a file\n",
        "  If the point has a positive slope, it is red\n",
        "  If the point has a negative slope, it is green\n",
        "  Otherwise, it is black\n",
        "  df: dataframe\n",
        "    the dataframe of which to graph the blink blendshapes\n",
        "  \"\"\"\n",
        "  for i in range(len(dfs)):\n",
        "    fig, ax = plt.subplots(2, 1, figsize = (8, 12))\n",
        "    peaksAndValleysGraph(\"eyeBlink_L\", dfs[i], fig, ax[0])\n",
        "    ax[0].set_title(\"eyeBlink_L\")\n",
        "    peaksAndValleysGraph(\"eyeBlink_R\", dfs[i], fig, ax[1])\n",
        "    ax[1].set_title(\"eyeBlink_R\")\n",
        "    saveGraph(fig, f\"{names[i]} Blink Graphs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSFn9fmItV_0"
      },
      "source": [
        "#Difference Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNgxlirbxmm8"
      },
      "source": [
        "##General Difference Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "2_KwCrKAtY9Y"
      },
      "outputs": [],
      "source": [
        "def difference(df1, colTitle1, colTitle2):\n",
        "  totalgraphs = 3\n",
        "  y1 = df1[colTitle1]\n",
        "  y2 = df1[colTitle2]\n",
        "  y3 = y1-y2\n",
        "  fig, ax = plt.subplots(totalgraphs, 1, figsize = (8, 6*totalgraphs))\n",
        "  ax[0].plot(df1[Milliseconds],y1, label = f\"{colTitle1}\")\n",
        "  ax[1].plot(df1[Milliseconds],y2, label = f\"{colTitle2}\")\n",
        "  ax[2].plot(df1[Milliseconds],y3, label = f\"Difference between {colTitle1} and {colTitle2}\")\n",
        "  for i in range (0,2):\n",
        "    ax[i].legend()\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "vBY4rhnsvxg0"
      },
      "outputs": [],
      "source": [
        "def differenceToFile(df1, colTitle1, colTitle2):\n",
        "  fig = difference(df1, colTitle1, colTitle2)\n",
        "  saveGraph(fig, f\"Difference between {colTitle1} and {colTitle2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51td5Ncwxow8"
      },
      "source": [
        "##Eye Difference Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "UmDmdvvcrfjJ"
      },
      "outputs": [],
      "source": [
        "def eyeDifference(dfs=[], names=[], scaledDifference = False):\n",
        "  \"\"\"\n",
        "  outputs graphs of the Left Eye and Right Eye x- and y- eulerAngles\n",
        "  dfs: list\n",
        "    the dataframes for data to be drawn from\n",
        "  scaledDifference: boolean\n",
        "    whether or not the y bounds will be the same for both graphs\n",
        "\n",
        "  returns: graphs of the Left Eye and Right Eye x- and y- eulerAngles\n",
        "  \"\"\"\n",
        "  fig, ax = plt.subplots(3, 2*len(dfs), figsize = (8*2*len(dfs), 6*3))\n",
        "\n",
        "  for q in range(len(dfs)):\n",
        "    for i in range(0+2*q,2+2*q):\n",
        "      if i == 0:\n",
        "        colTitle1 = \"LE x\"\n",
        "        colTitle2 = \"RE x\"\n",
        "      if i == 1:\n",
        "        colTitle1 = \"LE y\"\n",
        "        colTitle2 = \"RE y\"\n",
        "\n",
        "      y1 = dfs[q][colTitle1]\n",
        "      y2 = dfs[q][colTitle2]\n",
        "      y3 = y1-y2\n",
        "      ax[0,i].plot(dfs[q][Milliseconds],y1, label = f\"{colTitle1}\")\n",
        "      ax[1,i].plot(dfs[q][Milliseconds],y2, label = f\"{colTitle2}\")\n",
        "      ax[2,i].plot(dfs[q][Milliseconds],y3, label = f\"{colTitle1} - {colTitle2}\")\n",
        "      for j in range(0,3):\n",
        "        if j == 0 or j == 1:\n",
        "          ax[j,i].set_ylim(-30, 30)\n",
        "        ax[j,i].legend()\n",
        "        ax[j,i].set_title(names[q])\n",
        "\n",
        "    if scaledDifference == True:\n",
        "      ymin0, ymax0 = ax[2,0].get_ylim()\n",
        "      ymin1, ymax1 = ax[2,1].get_ylim()\n",
        "      if ymin1 < ymin0:\n",
        "        ymin = ymin1\n",
        "      if ymin1 > ymin0:\n",
        "        ymin = ymin0\n",
        "      if ymax1 < ymax0:\n",
        "        ymax = ymax0\n",
        "      if ymax1 > ymax0:\n",
        "        ymax = ymax1\n",
        "      ax[2,0].set_ylim(ymin, ymax)\n",
        "      ax[2,1].set_ylim(ymin, ymax)\n",
        "  return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "pHj-3XBRyaZk"
      },
      "outputs": [],
      "source": [
        "def eyeDifferenceToFile(dfs = [], names = [], scaledDifference = False):\n",
        "  fig = eyeDifference(dfs, names, scaledDifference)\n",
        "  nametotal = \"\"\n",
        "  for index in range(len(names)):\n",
        "    nametotal = nametotal + names[index] + \"-\"\n",
        "  saveGraph(fig, f\"{nametotal}LE-RE Difference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUO92M6HG2mW"
      },
      "source": [
        "#End Function (FINAL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "edohocOoPPh7"
      },
      "outputs": [],
      "source": [
        "# if you are using one of the above functions and want to zoom in on a graph, you can enable or disable zooming by\n",
        "# uncommenting one of the lines below and running this cell\n",
        "# Enable Zoom:\n",
        "# mpld3.enable_notebook()\n",
        "# Disable Zoom:\n",
        "# mpld3.disable_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "yGBr92XIG64I"
      },
      "outputs": [],
      "source": [
        "def outputAllDataAnalysis(dfs = [], names = [], skinnyGraph = True, scaled = True, individualColPairs = False, scaledDifference = False):\n",
        "  symmetryValuesToFile(dfs, names)\n",
        "  averageValuesToFile(dfs, names, individualColPairs)\n",
        "  graphAllToFile(dfs, names, True, False)\n",
        "  eyeDifferenceToFile(dfs, names, scaledDifference)\n",
        "  BlinkGraphsToFile(dfs, names)\n",
        "  if len(dfs) > 1:\n",
        "    compareSymmetryGraphsToFile(dfs, names, skinnyGraph, scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BybkKrM5Nu14"
      },
      "source": [
        "#Running Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywR8QPbt5kJ_"
      },
      "outputs": [],
      "source": [
        "outputAllDataAnalysis(dfs, dfsNames, True, False, False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1sQahL-K5DcMqxBymblCXkXXkwvWdVFRq",
      "authorship_tag": "ABX9TyP7YgRVbpR8XnpQxFsVZTCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}